{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Semarang, Jawa Tengah</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cirebon, Jawa Barat</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>Palembang, Sumatera Selatan</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>Bogor, Jawa Barat</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>Sragen, Jawa Tengah</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>Ponorogo, Jawa Timur</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_Id                     Location  Age\n",
       "0          1        Semarang, Jawa Tengah   20\n",
       "1          2           Bekasi, Jawa Barat   21\n",
       "2          3          Cirebon, Jawa Barat   23\n",
       "3          4           Bekasi, Jawa Barat   21\n",
       "4          5    Lampung, Sumatera Selatan   20\n",
       "..       ...                          ...  ...\n",
       "295      296    Lampung, Sumatera Selatan   31\n",
       "296      297  Palembang, Sumatera Selatan   39\n",
       "297      298            Bogor, Jawa Barat   38\n",
       "298      299          Sragen, Jawa Tengah   27\n",
       "299      300         Ponorogo, Jawa Timur   26\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = pd.read_csv(\"../data/datasets/user.csv\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings\n",
       "0           1       179              3\n",
       "1           1       344              2\n",
       "2           1         5              5\n",
       "3           1       373              3\n",
       "4           1       101              4\n",
       "...       ...       ...            ...\n",
       "9995      300       425              2\n",
       "9996      300        64              4\n",
       "9997      300       311              3\n",
       "9998      300       279              4\n",
       "9999      300       163              2\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat = pd.read_csv(\"../data/datasets/tourism_rating.csv\")\n",
    "rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time_Minutes</th>\n",
       "      <th>Coordinate</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>new_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monumen Nasional</td>\n",
       "      <td>Monumen Nasional atau yang populer disingkat d...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>20000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>{'lat': -6.1753924, 'lng': 106.8271528}</td>\n",
       "      <td>-6.175392</td>\n",
       "      <td>106.827153</td>\n",
       "      <td>['Budaya', 'Keluarga']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Kota Tua</td>\n",
       "      <td>Kota tua di Jakarta, yang juga bernama Kota Tu...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>{'lat': -6.137644799999999, 'lng': 106.8171245}</td>\n",
       "      <td>-6.137645</td>\n",
       "      <td>106.817125</td>\n",
       "      <td>['Budaya']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dunia Fantasi</td>\n",
       "      <td>Dunia Fantasi atau disebut juga Dufan adalah t...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>270000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>360.0</td>\n",
       "      <td>{'lat': -6.125312399999999, 'lng': 106.8335377}</td>\n",
       "      <td>-6.125312</td>\n",
       "      <td>106.833538</td>\n",
       "      <td>['Hiburan', 'Keluarga']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
       "      <td>Taman Mini Indonesia Indah merupakan suatu kaw...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -6.302445899999999, 'lng': 106.8951559}</td>\n",
       "      <td>-6.302446</td>\n",
       "      <td>106.895156</td>\n",
       "      <td>['Budaya', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlantis Water Adventure</td>\n",
       "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>94000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'lat': -6.12419, 'lng': 106.839134}</td>\n",
       "      <td>-6.124190</td>\n",
       "      <td>106.839134</td>\n",
       "      <td>['Petualangan', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>433</td>\n",
       "      <td>Museum Mpu Tantular</td>\n",
       "      <td>Museum Negeri Mpu Tantular adalah sebuah museu...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>{'lat': -7.4338593, 'lng': 112.7199058}</td>\n",
       "      <td>-7.433859</td>\n",
       "      <td>112.719906</td>\n",
       "      <td>['Sejarah', 'Budaya']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>434</td>\n",
       "      <td>Taman Bungkul</td>\n",
       "      <td>Taman Bungkul adalah taman wisata kota yang te...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.291346799999999, 'lng': 112.7398218}</td>\n",
       "      <td>-7.291347</td>\n",
       "      <td>112.739822</td>\n",
       "      <td>['Alam', 'Relaksasi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>435</td>\n",
       "      <td>Taman Air Mancur Menari Kenjeran</td>\n",
       "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>{'lat': -7.2752955, 'lng': 112.7549381}</td>\n",
       "      <td>-7.275296</td>\n",
       "      <td>112.754938</td>\n",
       "      <td>['Alam', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>Taman Flora Bratang Surabaya</td>\n",
       "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.294330299999999, 'lng': 112.7617534}</td>\n",
       "      <td>-7.294330</td>\n",
       "      <td>112.761753</td>\n",
       "      <td>['Alam', 'Relaksasi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>437</td>\n",
       "      <td>Gereja Perawan Maria Tak Berdosa Surabaya</td>\n",
       "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.2420758, 'lng': 112.7368158}</td>\n",
       "      <td>-7.242076</td>\n",
       "      <td>112.736816</td>\n",
       "      <td>['Budaya']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Place_Id                                 Place_Name  \\\n",
       "0           1                           Monumen Nasional   \n",
       "1           2                                   Kota Tua   \n",
       "2           3                              Dunia Fantasi   \n",
       "3           4          Taman Mini Indonesia Indah (TMII)   \n",
       "4           5                   Atlantis Water Adventure   \n",
       "..        ...                                        ...   \n",
       "432       433                        Museum Mpu Tantular   \n",
       "433       434                              Taman Bungkul   \n",
       "434       435           Taman Air Mancur Menari Kenjeran   \n",
       "435       436               Taman Flora Bratang Surabaya   \n",
       "436       437  Gereja Perawan Maria Tak Berdosa Surabaya   \n",
       "\n",
       "                                           Description      City   Price  \\\n",
       "0    Monumen Nasional atau yang populer disingkat d...   Jakarta   20000   \n",
       "1    Kota tua di Jakarta, yang juga bernama Kota Tu...   Jakarta       0   \n",
       "2    Dunia Fantasi atau disebut juga Dufan adalah t...   Jakarta  270000   \n",
       "3    Taman Mini Indonesia Indah merupakan suatu kaw...   Jakarta   10000   \n",
       "4    Atlantis Water Adventure atau dikenal dengan A...   Jakarta   94000   \n",
       "..                                                 ...       ...     ...   \n",
       "432  Museum Negeri Mpu Tantular adalah sebuah museu...  Surabaya    2000   \n",
       "433  Taman Bungkul adalah taman wisata kota yang te...  Surabaya       0   \n",
       "434  Air mancur menari atau dancing fountain juga a...  Surabaya       0   \n",
       "435  Taman Flora adalah salah satu taman kota di Su...  Surabaya       0   \n",
       "436  Gereja Katolik Kelahiran Santa Perawan Maria m...  Surabaya   10000   \n",
       "\n",
       "     Rating  Time_Minutes                                       Coordinate  \\\n",
       "0       4.6          15.0          {'lat': -6.1753924, 'lng': 106.8271528}   \n",
       "1       4.6          90.0  {'lat': -6.137644799999999, 'lng': 106.8171245}   \n",
       "2       4.6         360.0  {'lat': -6.125312399999999, 'lng': 106.8335377}   \n",
       "3       4.5           NaN  {'lat': -6.302445899999999, 'lng': 106.8951559}   \n",
       "4       4.5          60.0             {'lat': -6.12419, 'lng': 106.839134}   \n",
       "..      ...           ...                                              ...   \n",
       "432     4.4          45.0          {'lat': -7.4338593, 'lng': 112.7199058}   \n",
       "433     4.6           NaN  {'lat': -7.291346799999999, 'lng': 112.7398218}   \n",
       "434     4.4          45.0          {'lat': -7.2752955, 'lng': 112.7549381}   \n",
       "435     4.6           NaN  {'lat': -7.294330299999999, 'lng': 112.7617534}   \n",
       "436     4.8           NaN          {'lat': -7.2420758, 'lng': 112.7368158}   \n",
       "\n",
       "          Lat        Long                new_category  \n",
       "0   -6.175392  106.827153      ['Budaya', 'Keluarga']  \n",
       "1   -6.137645  106.817125                  ['Budaya']  \n",
       "2   -6.125312  106.833538     ['Hiburan', 'Keluarga']  \n",
       "3   -6.302446  106.895156       ['Budaya', 'Hiburan']  \n",
       "4   -6.124190  106.839134  ['Petualangan', 'Hiburan']  \n",
       "..        ...         ...                         ...  \n",
       "432 -7.433859  112.719906       ['Sejarah', 'Budaya']  \n",
       "433 -7.291347  112.739822       ['Alam', 'Relaksasi']  \n",
       "434 -7.275296  112.754938         ['Alam', 'Hiburan']  \n",
       "435 -7.294330  112.761753       ['Alam', 'Relaksasi']  \n",
       "436 -7.242076  112.736816                  ['Budaya']  \n",
       "\n",
       "[437 rows x 11 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update = pd.read_csv('../data/datasets/updated/tourism_with_id_updated.csv')\n",
    "update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list User_Id :  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300]\n",
      "encoded User_Id :  {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299}\n",
      "decode angka ke User_Id :  {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60, 60: 61, 61: 62, 62: 63, 63: 64, 64: 65, 65: 66, 66: 67, 67: 68, 68: 69, 69: 70, 70: 71, 71: 72, 72: 73, 73: 74, 74: 75, 75: 76, 76: 77, 77: 78, 78: 79, 79: 80, 80: 81, 81: 82, 82: 83, 83: 84, 84: 85, 85: 86, 86: 87, 87: 88, 88: 89, 89: 90, 90: 91, 91: 92, 92: 93, 93: 94, 94: 95, 95: 96, 96: 97, 97: 98, 98: 99, 99: 100, 100: 101, 101: 102, 102: 103, 103: 104, 104: 105, 105: 106, 106: 107, 107: 108, 108: 109, 109: 110, 110: 111, 111: 112, 112: 113, 113: 114, 114: 115, 115: 116, 116: 117, 117: 118, 118: 119, 119: 120, 120: 121, 121: 122, 122: 123, 123: 124, 124: 125, 125: 126, 126: 127, 127: 128, 128: 129, 129: 130, 130: 131, 131: 132, 132: 133, 133: 134, 134: 135, 135: 136, 136: 137, 137: 138, 138: 139, 139: 140, 140: 141, 141: 142, 142: 143, 143: 144, 144: 145, 145: 146, 146: 147, 147: 148, 148: 149, 149: 150, 150: 151, 151: 152, 152: 153, 153: 154, 154: 155, 155: 156, 156: 157, 157: 158, 158: 159, 159: 160, 160: 161, 161: 162, 162: 163, 163: 164, 164: 165, 165: 166, 166: 167, 167: 168, 168: 169, 169: 170, 170: 171, 171: 172, 172: 173, 173: 174, 174: 175, 175: 176, 176: 177, 177: 178, 178: 179, 179: 180, 180: 181, 181: 182, 182: 183, 183: 184, 184: 185, 185: 186, 186: 187, 187: 188, 188: 189, 189: 190, 190: 191, 191: 192, 192: 193, 193: 194, 194: 195, 195: 196, 196: 197, 197: 198, 198: 199, 199: 200, 200: 201, 201: 202, 202: 203, 203: 204, 204: 205, 205: 206, 206: 207, 207: 208, 208: 209, 209: 210, 210: 211, 211: 212, 212: 213, 213: 214, 214: 215, 215: 216, 216: 217, 217: 218, 218: 219, 219: 220, 220: 221, 221: 222, 222: 223, 223: 224, 224: 225, 225: 226, 226: 227, 227: 228, 228: 229, 229: 230, 230: 231, 231: 232, 232: 233, 233: 234, 234: 235, 235: 236, 236: 237, 237: 238, 238: 239, 239: 240, 240: 241, 241: 242, 242: 243, 243: 244, 244: 245, 245: 246, 246: 247, 247: 248, 248: 249, 249: 250, 250: 251, 251: 252, 252: 253, 253: 254, 254: 255, 255: 256, 256: 257, 257: 258, 258: 259, 259: 260, 260: 261, 261: 262, 262: 263, 263: 264, 264: 265, 265: 266, 266: 267, 267: 268, 268: 269, 269: 270, 270: 271, 271: 272, 272: 273, 273: 274, 274: 275, 275: 276, 276: 277, 277: 278, 278: 279, 279: 280, 280: 281, 281: 282, 282: 283, 283: 284, 284: 285, 285: 286, 286: 287, 287: 288, 288: 289, 289: 290, 290: 291, 291: 292, 292: 293, 293: 294, 294: 295, 295: 296, 296: 297, 297: 298, 298: 299, 299: 300}\n"
     ]
    }
   ],
   "source": [
    "user_ids = rat['User_Id'].unique().tolist()\n",
    "print('list User_Id : ', user_ids)\n",
    "\n",
    "user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "print('encoded User_Id : ', user_to_user_encoded)\n",
    "\n",
    "user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}\n",
    "print('decode angka ke User_Id : ', user_encoded_to_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list Place_Id :  [179, 344, 5, 373, 101, 312, 258, 20, 154, 393, 103, 208, 89, 405, 41, 336, 67, 292, 222, 76, 428, 15, 246, 265, 21, 328, 307, 302, 48, 147, 2, 322, 23, 85, 371, 78, 111, 107, 185, 413, 389, 437, 105, 176, 407, 281, 167, 384, 426, 390, 367, 166, 18, 321, 262, 223, 17, 319, 310, 421, 202, 283, 250, 118, 54, 70, 33, 227, 86, 249, 131, 382, 193, 104, 24, 128, 134, 228, 237, 100, 198, 50, 376, 268, 242, 82, 348, 409, 88, 4, 377, 43, 91, 44, 14, 406, 383, 229, 290, 294, 309, 74, 97, 138, 436, 395, 300, 68, 55, 434, 9, 151, 61, 159, 397, 391, 301, 143, 27, 190, 346, 381, 368, 433, 420, 335, 115, 334, 219, 178, 266, 92, 64, 102, 257, 243, 116, 359, 121, 385, 398, 119, 298, 410, 224, 379, 255, 269, 213, 126, 192, 183, 129, 303, 296, 99, 148, 13, 247, 31, 77, 158, 306, 98, 235, 45, 173, 275, 25, 130, 164, 267, 56, 30, 238, 402, 196, 417, 304, 206, 211, 28, 264, 403, 253, 331, 188, 416, 378, 233, 95, 204, 225, 341, 145, 36, 168, 12, 280, 236, 42, 90, 75, 63, 205, 234, 284, 230, 197, 339, 35, 226, 430, 37, 109, 355, 186, 149, 6, 150, 11, 127, 429, 194, 49, 369, 94, 274, 72, 46, 65, 203, 139, 141, 71, 52, 293, 422, 214, 114, 191, 156, 177, 163, 142, 245, 325, 259, 396, 96, 8, 362, 435, 59, 171, 277, 342, 365, 340, 260, 187, 297, 207, 248, 153, 239, 360, 170, 357, 73, 201, 252, 414, 132, 26, 347, 270, 16, 19, 318, 256, 181, 199, 288, 330, 3, 47, 32, 308, 210, 279, 289, 332, 80, 375, 182, 412, 272, 184, 113, 399, 261, 112, 327, 418, 84, 400, 195, 34, 295, 38, 165, 212, 124, 432, 317, 333, 81, 374, 136, 278, 108, 404, 83, 425, 22, 349, 411, 241, 427, 209, 323, 137, 315, 62, 244, 135, 169, 366, 152, 29, 60, 240, 200, 161, 66, 372, 338, 311, 53, 392, 299, 386, 337, 326, 423, 352, 172, 286, 251, 162, 356, 93, 160, 125, 316, 123, 174, 221, 408, 263, 358, 353, 401, 364, 215, 110, 144, 40, 291, 431, 120, 216, 313, 157, 282, 231, 324, 329, 345, 39, 273, 122, 79, 388, 380, 343, 254, 117, 133, 1, 354, 287, 155, 285, 58, 69, 305, 218, 220, 189, 106, 87, 351, 363, 175, 180, 415, 387, 394, 424, 146, 232, 314, 320, 276, 217, 57, 51, 361, 419, 271, 370, 350, 10, 7, 140]\n",
      "encoded Place_Id :  {179: 0, 344: 1, 5: 2, 373: 3, 101: 4, 312: 5, 258: 6, 20: 7, 154: 8, 393: 9, 103: 10, 208: 11, 89: 12, 405: 13, 41: 14, 336: 15, 67: 16, 292: 17, 222: 18, 76: 19, 428: 20, 15: 21, 246: 22, 265: 23, 21: 24, 328: 25, 307: 26, 302: 27, 48: 28, 147: 29, 2: 30, 322: 31, 23: 32, 85: 33, 371: 34, 78: 35, 111: 36, 107: 37, 185: 38, 413: 39, 389: 40, 437: 41, 105: 42, 176: 43, 407: 44, 281: 45, 167: 46, 384: 47, 426: 48, 390: 49, 367: 50, 166: 51, 18: 52, 321: 53, 262: 54, 223: 55, 17: 56, 319: 57, 310: 58, 421: 59, 202: 60, 283: 61, 250: 62, 118: 63, 54: 64, 70: 65, 33: 66, 227: 67, 86: 68, 249: 69, 131: 70, 382: 71, 193: 72, 104: 73, 24: 74, 128: 75, 134: 76, 228: 77, 237: 78, 100: 79, 198: 80, 50: 81, 376: 82, 268: 83, 242: 84, 82: 85, 348: 86, 409: 87, 88: 88, 4: 89, 377: 90, 43: 91, 91: 92, 44: 93, 14: 94, 406: 95, 383: 96, 229: 97, 290: 98, 294: 99, 309: 100, 74: 101, 97: 102, 138: 103, 436: 104, 395: 105, 300: 106, 68: 107, 55: 108, 434: 109, 9: 110, 151: 111, 61: 112, 159: 113, 397: 114, 391: 115, 301: 116, 143: 117, 27: 118, 190: 119, 346: 120, 381: 121, 368: 122, 433: 123, 420: 124, 335: 125, 115: 126, 334: 127, 219: 128, 178: 129, 266: 130, 92: 131, 64: 132, 102: 133, 257: 134, 243: 135, 116: 136, 359: 137, 121: 138, 385: 139, 398: 140, 119: 141, 298: 142, 410: 143, 224: 144, 379: 145, 255: 146, 269: 147, 213: 148, 126: 149, 192: 150, 183: 151, 129: 152, 303: 153, 296: 154, 99: 155, 148: 156, 13: 157, 247: 158, 31: 159, 77: 160, 158: 161, 306: 162, 98: 163, 235: 164, 45: 165, 173: 166, 275: 167, 25: 168, 130: 169, 164: 170, 267: 171, 56: 172, 30: 173, 238: 174, 402: 175, 196: 176, 417: 177, 304: 178, 206: 179, 211: 180, 28: 181, 264: 182, 403: 183, 253: 184, 331: 185, 188: 186, 416: 187, 378: 188, 233: 189, 95: 190, 204: 191, 225: 192, 341: 193, 145: 194, 36: 195, 168: 196, 12: 197, 280: 198, 236: 199, 42: 200, 90: 201, 75: 202, 63: 203, 205: 204, 234: 205, 284: 206, 230: 207, 197: 208, 339: 209, 35: 210, 226: 211, 430: 212, 37: 213, 109: 214, 355: 215, 186: 216, 149: 217, 6: 218, 150: 219, 11: 220, 127: 221, 429: 222, 194: 223, 49: 224, 369: 225, 94: 226, 274: 227, 72: 228, 46: 229, 65: 230, 203: 231, 139: 232, 141: 233, 71: 234, 52: 235, 293: 236, 422: 237, 214: 238, 114: 239, 191: 240, 156: 241, 177: 242, 163: 243, 142: 244, 245: 245, 325: 246, 259: 247, 396: 248, 96: 249, 8: 250, 362: 251, 435: 252, 59: 253, 171: 254, 277: 255, 342: 256, 365: 257, 340: 258, 260: 259, 187: 260, 297: 261, 207: 262, 248: 263, 153: 264, 239: 265, 360: 266, 170: 267, 357: 268, 73: 269, 201: 270, 252: 271, 414: 272, 132: 273, 26: 274, 347: 275, 270: 276, 16: 277, 19: 278, 318: 279, 256: 280, 181: 281, 199: 282, 288: 283, 330: 284, 3: 285, 47: 286, 32: 287, 308: 288, 210: 289, 279: 290, 289: 291, 332: 292, 80: 293, 375: 294, 182: 295, 412: 296, 272: 297, 184: 298, 113: 299, 399: 300, 261: 301, 112: 302, 327: 303, 418: 304, 84: 305, 400: 306, 195: 307, 34: 308, 295: 309, 38: 310, 165: 311, 212: 312, 124: 313, 432: 314, 317: 315, 333: 316, 81: 317, 374: 318, 136: 319, 278: 320, 108: 321, 404: 322, 83: 323, 425: 324, 22: 325, 349: 326, 411: 327, 241: 328, 427: 329, 209: 330, 323: 331, 137: 332, 315: 333, 62: 334, 244: 335, 135: 336, 169: 337, 366: 338, 152: 339, 29: 340, 60: 341, 240: 342, 200: 343, 161: 344, 66: 345, 372: 346, 338: 347, 311: 348, 53: 349, 392: 350, 299: 351, 386: 352, 337: 353, 326: 354, 423: 355, 352: 356, 172: 357, 286: 358, 251: 359, 162: 360, 356: 361, 93: 362, 160: 363, 125: 364, 316: 365, 123: 366, 174: 367, 221: 368, 408: 369, 263: 370, 358: 371, 353: 372, 401: 373, 364: 374, 215: 375, 110: 376, 144: 377, 40: 378, 291: 379, 431: 380, 120: 381, 216: 382, 313: 383, 157: 384, 282: 385, 231: 386, 324: 387, 329: 388, 345: 389, 39: 390, 273: 391, 122: 392, 79: 393, 388: 394, 380: 395, 343: 396, 254: 397, 117: 398, 133: 399, 1: 400, 354: 401, 287: 402, 155: 403, 285: 404, 58: 405, 69: 406, 305: 407, 218: 408, 220: 409, 189: 410, 106: 411, 87: 412, 351: 413, 363: 414, 175: 415, 180: 416, 415: 417, 387: 418, 394: 419, 424: 420, 146: 421, 232: 422, 314: 423, 320: 424, 276: 425, 217: 426, 57: 427, 51: 428, 361: 429, 419: 430, 271: 431, 370: 432, 350: 433, 10: 434, 7: 435, 140: 436}\n",
      "decode angka ke Place_Id :  {0: 179, 1: 344, 2: 5, 3: 373, 4: 101, 5: 312, 6: 258, 7: 20, 8: 154, 9: 393, 10: 103, 11: 208, 12: 89, 13: 405, 14: 41, 15: 336, 16: 67, 17: 292, 18: 222, 19: 76, 20: 428, 21: 15, 22: 246, 23: 265, 24: 21, 25: 328, 26: 307, 27: 302, 28: 48, 29: 147, 30: 2, 31: 322, 32: 23, 33: 85, 34: 371, 35: 78, 36: 111, 37: 107, 38: 185, 39: 413, 40: 389, 41: 437, 42: 105, 43: 176, 44: 407, 45: 281, 46: 167, 47: 384, 48: 426, 49: 390, 50: 367, 51: 166, 52: 18, 53: 321, 54: 262, 55: 223, 56: 17, 57: 319, 58: 310, 59: 421, 60: 202, 61: 283, 62: 250, 63: 118, 64: 54, 65: 70, 66: 33, 67: 227, 68: 86, 69: 249, 70: 131, 71: 382, 72: 193, 73: 104, 74: 24, 75: 128, 76: 134, 77: 228, 78: 237, 79: 100, 80: 198, 81: 50, 82: 376, 83: 268, 84: 242, 85: 82, 86: 348, 87: 409, 88: 88, 89: 4, 90: 377, 91: 43, 92: 91, 93: 44, 94: 14, 95: 406, 96: 383, 97: 229, 98: 290, 99: 294, 100: 309, 101: 74, 102: 97, 103: 138, 104: 436, 105: 395, 106: 300, 107: 68, 108: 55, 109: 434, 110: 9, 111: 151, 112: 61, 113: 159, 114: 397, 115: 391, 116: 301, 117: 143, 118: 27, 119: 190, 120: 346, 121: 381, 122: 368, 123: 433, 124: 420, 125: 335, 126: 115, 127: 334, 128: 219, 129: 178, 130: 266, 131: 92, 132: 64, 133: 102, 134: 257, 135: 243, 136: 116, 137: 359, 138: 121, 139: 385, 140: 398, 141: 119, 142: 298, 143: 410, 144: 224, 145: 379, 146: 255, 147: 269, 148: 213, 149: 126, 150: 192, 151: 183, 152: 129, 153: 303, 154: 296, 155: 99, 156: 148, 157: 13, 158: 247, 159: 31, 160: 77, 161: 158, 162: 306, 163: 98, 164: 235, 165: 45, 166: 173, 167: 275, 168: 25, 169: 130, 170: 164, 171: 267, 172: 56, 173: 30, 174: 238, 175: 402, 176: 196, 177: 417, 178: 304, 179: 206, 180: 211, 181: 28, 182: 264, 183: 403, 184: 253, 185: 331, 186: 188, 187: 416, 188: 378, 189: 233, 190: 95, 191: 204, 192: 225, 193: 341, 194: 145, 195: 36, 196: 168, 197: 12, 198: 280, 199: 236, 200: 42, 201: 90, 202: 75, 203: 63, 204: 205, 205: 234, 206: 284, 207: 230, 208: 197, 209: 339, 210: 35, 211: 226, 212: 430, 213: 37, 214: 109, 215: 355, 216: 186, 217: 149, 218: 6, 219: 150, 220: 11, 221: 127, 222: 429, 223: 194, 224: 49, 225: 369, 226: 94, 227: 274, 228: 72, 229: 46, 230: 65, 231: 203, 232: 139, 233: 141, 234: 71, 235: 52, 236: 293, 237: 422, 238: 214, 239: 114, 240: 191, 241: 156, 242: 177, 243: 163, 244: 142, 245: 245, 246: 325, 247: 259, 248: 396, 249: 96, 250: 8, 251: 362, 252: 435, 253: 59, 254: 171, 255: 277, 256: 342, 257: 365, 258: 340, 259: 260, 260: 187, 261: 297, 262: 207, 263: 248, 264: 153, 265: 239, 266: 360, 267: 170, 268: 357, 269: 73, 270: 201, 271: 252, 272: 414, 273: 132, 274: 26, 275: 347, 276: 270, 277: 16, 278: 19, 279: 318, 280: 256, 281: 181, 282: 199, 283: 288, 284: 330, 285: 3, 286: 47, 287: 32, 288: 308, 289: 210, 290: 279, 291: 289, 292: 332, 293: 80, 294: 375, 295: 182, 296: 412, 297: 272, 298: 184, 299: 113, 300: 399, 301: 261, 302: 112, 303: 327, 304: 418, 305: 84, 306: 400, 307: 195, 308: 34, 309: 295, 310: 38, 311: 165, 312: 212, 313: 124, 314: 432, 315: 317, 316: 333, 317: 81, 318: 374, 319: 136, 320: 278, 321: 108, 322: 404, 323: 83, 324: 425, 325: 22, 326: 349, 327: 411, 328: 241, 329: 427, 330: 209, 331: 323, 332: 137, 333: 315, 334: 62, 335: 244, 336: 135, 337: 169, 338: 366, 339: 152, 340: 29, 341: 60, 342: 240, 343: 200, 344: 161, 345: 66, 346: 372, 347: 338, 348: 311, 349: 53, 350: 392, 351: 299, 352: 386, 353: 337, 354: 326, 355: 423, 356: 352, 357: 172, 358: 286, 359: 251, 360: 162, 361: 356, 362: 93, 363: 160, 364: 125, 365: 316, 366: 123, 367: 174, 368: 221, 369: 408, 370: 263, 371: 358, 372: 353, 373: 401, 374: 364, 375: 215, 376: 110, 377: 144, 378: 40, 379: 291, 380: 431, 381: 120, 382: 216, 383: 313, 384: 157, 385: 282, 386: 231, 387: 324, 388: 329, 389: 345, 390: 39, 391: 273, 392: 122, 393: 79, 394: 388, 395: 380, 396: 343, 397: 254, 398: 117, 399: 133, 400: 1, 401: 354, 402: 287, 403: 155, 404: 285, 405: 58, 406: 69, 407: 305, 408: 218, 409: 220, 410: 189, 411: 106, 412: 87, 413: 351, 414: 363, 415: 175, 416: 180, 417: 415, 418: 387, 419: 394, 420: 424, 421: 146, 422: 232, 423: 314, 424: 320, 425: 276, 426: 217, 427: 57, 428: 51, 429: 361, 430: 419, 431: 271, 432: 370, 433: 350, 434: 10, 435: 7, 436: 140}\n"
     ]
    }
   ],
   "source": [
    "place_ids = rat['Place_Id'].unique().tolist()\n",
    "print('list Place_Id : ', place_ids)\n",
    "\n",
    "place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}\n",
    "print('encoded Place_Id : ', place_to_place_encoded)\n",
    "\n",
    "place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}\n",
    "print('decode angka ke Place_Id : ', place_encoded_to_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings\n",
       "0           1       179              3\n",
       "1           1       344              2\n",
       "2           1         5              5\n",
       "3           1       373              3\n",
       "4           1       101              4\n",
       "...       ...       ...            ...\n",
       "9995      300       425              2\n",
       "9996      300        64              4\n",
       "9997      300       311              3\n",
       "9998      300       279              4\n",
       "9999      300       163              2\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "collfil = rat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "collfil['user'] = collfil['User_Id'].map(user_to_user_encoded)\n",
    "collfil['place'] = collfil['Place_Id'].map(place_to_place_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Count: 300\n",
      "Places Count: 437\n",
      "Min rating: 1.0\n",
      "Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_to_user_encoded)\n",
    "num_places = len(place_encoded_to_place)\n",
    "\n",
    "collfil['rating'] = collfil['Place_Ratings'].values.astype(np.float32)\n",
    "\n",
    "min_rating = min(collfil['rating'])\n",
    "max_rating = max(collfil['rating'])\n",
    "\n",
    "print(f'Users Count: {num_users}')\n",
    "print(f'Places Count: {num_places}')\n",
    "print(f'Min rating: {min_rating}')\n",
    "print(f'Max rating: {max_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "      <th>user</th>\n",
       "      <th>place</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>324</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>132</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>348</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>290</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>243</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings  user  place  rating\n",
       "0           1       179              3     0      0     3.0\n",
       "1           1       344              2     0      1     2.0\n",
       "2           1         5              5     0      2     5.0\n",
       "3           1       373              3     0      3     3.0\n",
       "4           1       101              4     0      4     4.0\n",
       "...       ...       ...            ...   ...    ...     ...\n",
       "9995      300       425              2   299    324     2.0\n",
       "9996      300        64              4   299    132     4.0\n",
       "9997      300       311              3   299    348     3.0\n",
       "9998      300       279              4   299    290     4.0\n",
       "9999      300       163              2   299    243     2.0\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = collfil[['user', 'place']].values\n",
    "\n",
    "y = collfil['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(tf.keras.Model):\n",
    " \n",
    "  # Insialisasi fungsi\n",
    "  def __init__(self, num_users, num_places, embedding_size, **kwargs):\n",
    "    super(RecommenderNet, self).__init__(**kwargs)\n",
    "    self.num_users = num_users\n",
    "    self.num_places = num_places\n",
    "    self.embedding_size = embedding_size\n",
    "    self.user_embedding = layers.Embedding( # layer embedding user\n",
    "        num_users,\n",
    "        embedding_size,\n",
    "        embeddings_initializer = 'he_normal',\n",
    "        embeddings_regularizer = keras.regularizers.l2(1e-6)\n",
    "    )\n",
    "    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias\n",
    "    self.places_embedding = layers.Embedding( # layer embeddings places\n",
    "        num_places,\n",
    "        embedding_size,\n",
    "        embeddings_initializer = 'he_normal',\n",
    "        embeddings_regularizer = keras.regularizers.l2(1e-6)\n",
    "    )\n",
    "    self.places_bias = layers.Embedding(num_places, 1) # layer embedding places bias\n",
    " \n",
    "  def call(self, inputs):\n",
    "    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1\n",
    "    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2\n",
    "    places_vector = self.places_embedding(inputs[:, 1]) # memanggil layer embedding 3\n",
    "    places_bias = self.places_bias(inputs[:, 1]) # memanggil layer embedding 4\n",
    " \n",
    "    dot_user_places = tf.tensordot(user_vector, places_vector, 2) \n",
    " \n",
    "    x = dot_user_places + user_bias + places_bias\n",
    "    \n",
    "    return tf.nn.sigmoid(x) # activation sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderNet(num_users, num_places, 50) # inisialisasi model\n",
    " \n",
    "# model compile\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0004),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(Callback):    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"Checking val_root_mean_squared_error at end of epoch...\")\n",
    "        if logs['val_root_mean_squared_error'] <= 0.25:\n",
    "               self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/210 [=======================>......] - ETA: 0s - loss: 0.7001 - root_mean_squared_error: 0.3485Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.6994 - root_mean_squared_error: 0.3487 - val_loss: 0.6962 - val_root_mean_squared_error: 0.3492\n",
      "Epoch 2/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6961 - root_mean_squared_error: 0.3458Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6970 - root_mean_squared_error: 0.3470 - val_loss: 0.6963 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 3/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6940 - root_mean_squared_error: 0.3453Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6945 - root_mean_squared_error: 0.3453 - val_loss: 0.6963 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 4/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6931 - root_mean_squared_error: 0.3450Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6936 - root_mean_squared_error: 0.3446 - val_loss: 0.6960 - val_root_mean_squared_error: 0.3491\n",
      "Epoch 5/100\n",
      "208/210 [============================>.] - ETA: 0s - loss: 0.6915 - root_mean_squared_error: 0.3432Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6915 - root_mean_squared_error: 0.3431 - val_loss: 0.6959 - val_root_mean_squared_error: 0.3490\n",
      "Epoch 6/100\n",
      "160/210 [=====================>........] - ETA: 0s - loss: 0.6915 - root_mean_squared_error: 0.3437Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6913 - root_mean_squared_error: 0.3430 - val_loss: 0.6958 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 7/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6893 - root_mean_squared_error: 0.3401Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6902 - root_mean_squared_error: 0.3422 - val_loss: 0.6957 - val_root_mean_squared_error: 0.3488\n",
      "Epoch 8/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6900 - root_mean_squared_error: 0.3417Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6899 - root_mean_squared_error: 0.3419 - val_loss: 0.6958 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 9/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6869 - root_mean_squared_error: 0.3403Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6873 - root_mean_squared_error: 0.3401 - val_loss: 0.6960 - val_root_mean_squared_error: 0.3490\n",
      "Epoch 10/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6855 - root_mean_squared_error: 0.3376Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6857 - root_mean_squared_error: 0.3389 - val_loss: 0.6957 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 11/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6868 - root_mean_squared_error: 0.3396Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6865 - root_mean_squared_error: 0.3395 - val_loss: 0.6958 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 12/100\n",
      "201/210 [===========================>..] - ETA: 0s - loss: 0.6855 - root_mean_squared_error: 0.3388Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6853 - root_mean_squared_error: 0.3386 - val_loss: 0.6956 - val_root_mean_squared_error: 0.3488\n",
      "Epoch 13/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6831 - root_mean_squared_error: 0.3374Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6831 - root_mean_squared_error: 0.3371 - val_loss: 0.6955 - val_root_mean_squared_error: 0.3487\n",
      "Epoch 14/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6847 - root_mean_squared_error: 0.3378Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6842 - root_mean_squared_error: 0.3378 - val_loss: 0.6957 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 15/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6832 - root_mean_squared_error: 0.3356Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6834 - root_mean_squared_error: 0.3372 - val_loss: 0.6955 - val_root_mean_squared_error: 0.3487\n",
      "Epoch 16/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6809 - root_mean_squared_error: 0.3359Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6822 - root_mean_squared_error: 0.3364 - val_loss: 0.6953 - val_root_mean_squared_error: 0.3486\n",
      "Epoch 17/100\n",
      "164/210 [======================>.......] - ETA: 0s - loss: 0.6796 - root_mean_squared_error: 0.3345Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6797 - root_mean_squared_error: 0.3346 - val_loss: 0.6957 - val_root_mean_squared_error: 0.3489\n",
      "Epoch 18/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6795 - root_mean_squared_error: 0.3342Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6791 - root_mean_squared_error: 0.3341 - val_loss: 0.6961 - val_root_mean_squared_error: 0.3491\n",
      "Epoch 19/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6803 - root_mean_squared_error: 0.3360Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6794 - root_mean_squared_error: 0.3343 - val_loss: 0.6963 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 20/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6782 - root_mean_squared_error: 0.3334Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6784 - root_mean_squared_error: 0.3336 - val_loss: 0.6962 - val_root_mean_squared_error: 0.3492\n",
      "Epoch 21/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6783 - root_mean_squared_error: 0.3312Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6780 - root_mean_squared_error: 0.3333 - val_loss: 0.6964 - val_root_mean_squared_error: 0.3493\n",
      "Epoch 22/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6758 - root_mean_squared_error: 0.3311Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6767 - root_mean_squared_error: 0.3323 - val_loss: 0.6965 - val_root_mean_squared_error: 0.3494\n",
      "Epoch 23/100\n",
      "207/210 [============================>.] - ETA: 0s - loss: 0.6755 - root_mean_squared_error: 0.3312Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6753 - root_mean_squared_error: 0.3313 - val_loss: 0.6965 - val_root_mean_squared_error: 0.3494\n",
      "Epoch 24/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6770 - root_mean_squared_error: 0.3332Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6757 - root_mean_squared_error: 0.3317 - val_loss: 0.6967 - val_root_mean_squared_error: 0.3495\n",
      "Epoch 25/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6729 - root_mean_squared_error: 0.3280Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6740 - root_mean_squared_error: 0.3304 - val_loss: 0.6969 - val_root_mean_squared_error: 0.3497\n",
      "Epoch 26/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6746 - root_mean_squared_error: 0.3312Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6746 - root_mean_squared_error: 0.3308 - val_loss: 0.6970 - val_root_mean_squared_error: 0.3497\n",
      "Epoch 27/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6737 - root_mean_squared_error: 0.3297Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6736 - root_mean_squared_error: 0.3301 - val_loss: 0.6971 - val_root_mean_squared_error: 0.3498\n",
      "Epoch 28/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6728 - root_mean_squared_error: 0.3296Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6731 - root_mean_squared_error: 0.3297 - val_loss: 0.6968 - val_root_mean_squared_error: 0.3496\n",
      "Epoch 29/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6705 - root_mean_squared_error: 0.3286Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6712 - root_mean_squared_error: 0.3283 - val_loss: 0.6970 - val_root_mean_squared_error: 0.3497\n",
      "Epoch 30/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6707 - root_mean_squared_error: 0.3274Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6716 - root_mean_squared_error: 0.3286 - val_loss: 0.6973 - val_root_mean_squared_error: 0.3499\n",
      "Epoch 31/100\n",
      "199/210 [===========================>..] - ETA: 0s - loss: 0.6729 - root_mean_squared_error: 0.3293Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6724 - root_mean_squared_error: 0.3292 - val_loss: 0.6977 - val_root_mean_squared_error: 0.3502\n",
      "Epoch 32/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6713 - root_mean_squared_error: 0.3288Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6711 - root_mean_squared_error: 0.3283 - val_loss: 0.6978 - val_root_mean_squared_error: 0.3503\n",
      "Epoch 33/100\n",
      "194/210 [==========================>...] - ETA: 0s - loss: 0.6710 - root_mean_squared_error: 0.3276Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6709 - root_mean_squared_error: 0.3281 - val_loss: 0.6977 - val_root_mean_squared_error: 0.3502\n",
      "Epoch 34/100\n",
      "176/210 [========================>.....] - ETA: 0s - loss: 0.6714 - root_mean_squared_error: 0.3290Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6706 - root_mean_squared_error: 0.3279 - val_loss: 0.6977 - val_root_mean_squared_error: 0.3502\n",
      "Epoch 35/100\n",
      "157/210 [=====================>........] - ETA: 0s - loss: 0.6690 - root_mean_squared_error: 0.3281Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6697 - root_mean_squared_error: 0.3272 - val_loss: 0.6980 - val_root_mean_squared_error: 0.3503\n",
      "Epoch 36/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6709 - root_mean_squared_error: 0.3279Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6703 - root_mean_squared_error: 0.3277 - val_loss: 0.6986 - val_root_mean_squared_error: 0.3508\n",
      "Epoch 37/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6705 - root_mean_squared_error: 0.3292Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6703 - root_mean_squared_error: 0.3277 - val_loss: 0.6986 - val_root_mean_squared_error: 0.3508\n",
      "Epoch 38/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6660 - root_mean_squared_error: 0.3245Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6673 - root_mean_squared_error: 0.3255 - val_loss: 0.6990 - val_root_mean_squared_error: 0.3510\n",
      "Epoch 39/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6675 - root_mean_squared_error: 0.3250Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6678 - root_mean_squared_error: 0.3258 - val_loss: 0.6991 - val_root_mean_squared_error: 0.3511\n",
      "Epoch 40/100\n",
      "176/210 [========================>.....] - ETA: 0s - loss: 0.6678 - root_mean_squared_error: 0.3260Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6680 - root_mean_squared_error: 0.3259 - val_loss: 0.6996 - val_root_mean_squared_error: 0.3514\n",
      "Epoch 41/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6671 - root_mean_squared_error: 0.3261Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6676 - root_mean_squared_error: 0.3257 - val_loss: 0.6998 - val_root_mean_squared_error: 0.3516\n",
      "Epoch 42/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6679 - root_mean_squared_error: 0.3276Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6678 - root_mean_squared_error: 0.3258 - val_loss: 0.6999 - val_root_mean_squared_error: 0.3517\n",
      "Epoch 43/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.6677 - root_mean_squared_error: 0.3257Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6677 - root_mean_squared_error: 0.3257 - val_loss: 0.7001 - val_root_mean_squared_error: 0.3518\n",
      "Epoch 44/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6671 - root_mean_squared_error: 0.3251Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6673 - root_mean_squared_error: 0.3255 - val_loss: 0.7004 - val_root_mean_squared_error: 0.3520\n",
      "Epoch 45/100\n",
      "176/210 [========================>.....] - ETA: 0s - loss: 0.6663 - root_mean_squared_error: 0.3249Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6667 - root_mean_squared_error: 0.3250 - val_loss: 0.7007 - val_root_mean_squared_error: 0.3522\n",
      "Epoch 46/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6641 - root_mean_squared_error: 0.3224Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6653 - root_mean_squared_error: 0.3240 - val_loss: 0.7006 - val_root_mean_squared_error: 0.3521\n",
      "Epoch 47/100\n",
      "176/210 [========================>.....] - ETA: 0s - loss: 0.6645 - root_mean_squared_error: 0.3227Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6646 - root_mean_squared_error: 0.3234 - val_loss: 0.7008 - val_root_mean_squared_error: 0.3523\n",
      "Epoch 48/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6661 - root_mean_squared_error: 0.3239Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6662 - root_mean_squared_error: 0.3246 - val_loss: 0.7013 - val_root_mean_squared_error: 0.3526\n",
      "Epoch 49/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6662 - root_mean_squared_error: 0.3258Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6663 - root_mean_squared_error: 0.3248 - val_loss: 0.7016 - val_root_mean_squared_error: 0.3528\n",
      "Epoch 50/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6651 - root_mean_squared_error: 0.3228Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6646 - root_mean_squared_error: 0.3235 - val_loss: 0.7018 - val_root_mean_squared_error: 0.3529\n",
      "Epoch 51/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6646 - root_mean_squared_error: 0.3238Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6656 - root_mean_squared_error: 0.3242 - val_loss: 0.7020 - val_root_mean_squared_error: 0.3531\n",
      "Epoch 52/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6637 - root_mean_squared_error: 0.3234Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6645 - root_mean_squared_error: 0.3234 - val_loss: 0.7023 - val_root_mean_squared_error: 0.3532\n",
      "Epoch 53/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6658 - root_mean_squared_error: 0.3213Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6645 - root_mean_squared_error: 0.3234 - val_loss: 0.7026 - val_root_mean_squared_error: 0.3534\n",
      "Epoch 54/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6642 - root_mean_squared_error: 0.3235Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6636 - root_mean_squared_error: 0.3228 - val_loss: 0.7031 - val_root_mean_squared_error: 0.3538\n",
      "Epoch 55/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.6642 - root_mean_squared_error: 0.3232Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6642 - root_mean_squared_error: 0.3232 - val_loss: 0.7034 - val_root_mean_squared_error: 0.3539\n",
      "Epoch 56/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6639 - root_mean_squared_error: 0.3246Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6640 - root_mean_squared_error: 0.3231 - val_loss: 0.7033 - val_root_mean_squared_error: 0.3539\n",
      "Epoch 57/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6639 - root_mean_squared_error: 0.3222Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6630 - root_mean_squared_error: 0.3223 - val_loss: 0.7036 - val_root_mean_squared_error: 0.3541\n",
      "Epoch 58/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6648 - root_mean_squared_error: 0.3224Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6642 - root_mean_squared_error: 0.3232 - val_loss: 0.7038 - val_root_mean_squared_error: 0.3542\n",
      "Epoch 59/100\n",
      "164/210 [======================>.......] - ETA: 0s - loss: 0.6630 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6630 - root_mean_squared_error: 0.3223 - val_loss: 0.7039 - val_root_mean_squared_error: 0.3543\n",
      "Epoch 60/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6628 - root_mean_squared_error: 0.3214Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6631 - root_mean_squared_error: 0.3224 - val_loss: 0.7044 - val_root_mean_squared_error: 0.3546\n",
      "Epoch 61/100\n",
      "198/210 [===========================>..] - ETA: 0s - loss: 0.6622 - root_mean_squared_error: 0.3228Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6619 - root_mean_squared_error: 0.3215 - val_loss: 0.7044 - val_root_mean_squared_error: 0.3546\n",
      "Epoch 62/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6623 - root_mean_squared_error: 0.3219Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6617 - root_mean_squared_error: 0.3213 - val_loss: 0.7048 - val_root_mean_squared_error: 0.3549\n",
      "Epoch 63/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6650 - root_mean_squared_error: 0.3245Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6637 - root_mean_squared_error: 0.3228 - val_loss: 0.7050 - val_root_mean_squared_error: 0.3550\n",
      "Epoch 64/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6620 - root_mean_squared_error: 0.3224Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6613 - root_mean_squared_error: 0.3211 - val_loss: 0.7053 - val_root_mean_squared_error: 0.3552\n",
      "Epoch 65/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6608 - root_mean_squared_error: 0.3219Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6621 - root_mean_squared_error: 0.3216 - val_loss: 0.7051 - val_root_mean_squared_error: 0.3551\n",
      "Epoch 66/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6619 - root_mean_squared_error: 0.3212Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6621 - root_mean_squared_error: 0.3217 - val_loss: 0.7053 - val_root_mean_squared_error: 0.3552\n",
      "Epoch 67/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6627 - root_mean_squared_error: 0.3209Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6624 - root_mean_squared_error: 0.3218 - val_loss: 0.7056 - val_root_mean_squared_error: 0.3554\n",
      "Epoch 68/100\n",
      "207/210 [============================>.] - ETA: 0s - loss: 0.6629 - root_mean_squared_error: 0.3219Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6628 - root_mean_squared_error: 0.3222 - val_loss: 0.7054 - val_root_mean_squared_error: 0.3553\n",
      "Epoch 69/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6622 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6620 - root_mean_squared_error: 0.3216 - val_loss: 0.7057 - val_root_mean_squared_error: 0.3554\n",
      "Epoch 70/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6617 - root_mean_squared_error: 0.3203Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6623 - root_mean_squared_error: 0.3218 - val_loss: 0.7058 - val_root_mean_squared_error: 0.3555\n",
      "Epoch 71/100\n",
      "198/210 [===========================>..] - ETA: 0s - loss: 0.6602 - root_mean_squared_error: 0.3208Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6611 - root_mean_squared_error: 0.3209 - val_loss: 0.7064 - val_root_mean_squared_error: 0.3559\n",
      "Epoch 72/100\n",
      "157/210 [=====================>........] - ETA: 0s - loss: 0.6619 - root_mean_squared_error: 0.3212Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6619 - root_mean_squared_error: 0.3216 - val_loss: 0.7066 - val_root_mean_squared_error: 0.3560\n",
      "Epoch 73/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6616 - root_mean_squared_error: 0.3229Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6615 - root_mean_squared_error: 0.3212 - val_loss: 0.7064 - val_root_mean_squared_error: 0.3559\n",
      "Epoch 74/100\n",
      "180/210 [========================>.....] - ETA: 0s - loss: 0.6594 - root_mean_squared_error: 0.3212Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6599 - root_mean_squared_error: 0.3200 - val_loss: 0.7063 - val_root_mean_squared_error: 0.3558\n",
      "Epoch 75/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3201Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6604 - root_mean_squared_error: 0.3204 - val_loss: 0.7066 - val_root_mean_squared_error: 0.3560\n",
      "Epoch 76/100\n",
      "175/210 [========================>.....] - ETA: 0s - loss: 0.6588 - root_mean_squared_error: 0.3200Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6598 - root_mean_squared_error: 0.3200 - val_loss: 0.7068 - val_root_mean_squared_error: 0.3561\n",
      "Epoch 77/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6628 - root_mean_squared_error: 0.3224Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6620 - root_mean_squared_error: 0.3216 - val_loss: 0.7066 - val_root_mean_squared_error: 0.3560\n",
      "Epoch 78/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3196Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6602 - root_mean_squared_error: 0.3202 - val_loss: 0.7067 - val_root_mean_squared_error: 0.3560\n",
      "Epoch 79/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6593 - root_mean_squared_error: 0.3202Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6602 - root_mean_squared_error: 0.3204 - val_loss: 0.7069 - val_root_mean_squared_error: 0.3562\n",
      "Epoch 80/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6603 - root_mean_squared_error: 0.3203Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6601 - root_mean_squared_error: 0.3202 - val_loss: 0.7068 - val_root_mean_squared_error: 0.3561\n",
      "Epoch 81/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6612 - root_mean_squared_error: 0.3187Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6611 - root_mean_squared_error: 0.3210 - val_loss: 0.7070 - val_root_mean_squared_error: 0.3563\n",
      "Epoch 82/100\n",
      "176/210 [========================>.....] - ETA: 0s - loss: 0.6602 - root_mean_squared_error: 0.3209Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6603 - root_mean_squared_error: 0.3203 - val_loss: 0.7073 - val_root_mean_squared_error: 0.3564\n",
      "Epoch 83/100\n",
      "203/210 [============================>.] - ETA: 0s - loss: 0.6598 - root_mean_squared_error: 0.3203Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6605 - root_mean_squared_error: 0.3204 - val_loss: 0.7073 - val_root_mean_squared_error: 0.3564\n",
      "Epoch 84/100\n",
      "208/210 [============================>.] - ETA: 0s - loss: 0.6614 - root_mean_squared_error: 0.3216Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6615 - root_mean_squared_error: 0.3213 - val_loss: 0.7077 - val_root_mean_squared_error: 0.3567\n",
      "Epoch 85/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6612 - root_mean_squared_error: 0.3213Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6609 - root_mean_squared_error: 0.3209 - val_loss: 0.7083 - val_root_mean_squared_error: 0.3571\n",
      "Epoch 86/100\n",
      "198/210 [===========================>..] - ETA: 0s - loss: 0.6605 - root_mean_squared_error: 0.3207Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6603 - root_mean_squared_error: 0.3204 - val_loss: 0.7084 - val_root_mean_squared_error: 0.3571\n",
      "Epoch 87/100\n",
      "187/210 [=========================>....] - ETA: 0s - loss: 0.6596 - root_mean_squared_error: 0.3195Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6602 - root_mean_squared_error: 0.3203 - val_loss: 0.7087 - val_root_mean_squared_error: 0.3573\n",
      "Epoch 88/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6589 - root_mean_squared_error: 0.3198Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6602 - root_mean_squared_error: 0.3203 - val_loss: 0.7091 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 89/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6600 - root_mean_squared_error: 0.3210Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6607 - root_mean_squared_error: 0.3207 - val_loss: 0.7090 - val_root_mean_squared_error: 0.3575\n",
      "Epoch 90/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6595 - root_mean_squared_error: 0.3195Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6602 - root_mean_squared_error: 0.3203 - val_loss: 0.7089 - val_root_mean_squared_error: 0.3575\n",
      "Epoch 91/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6578 - root_mean_squared_error: 0.3191Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6597 - root_mean_squared_error: 0.3199 - val_loss: 0.7092 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 92/100\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.6606 - root_mean_squared_error: 0.3206Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6606 - root_mean_squared_error: 0.3206 - val_loss: 0.7089 - val_root_mean_squared_error: 0.3575\n",
      "Epoch 93/100\n",
      "165/210 [======================>.......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3208Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6599 - root_mean_squared_error: 0.3201 - val_loss: 0.7091 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 94/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6606 - root_mean_squared_error: 0.3197Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6609 - root_mean_squared_error: 0.3208 - val_loss: 0.7093 - val_root_mean_squared_error: 0.3577\n",
      "Epoch 95/100\n",
      "183/210 [=========================>....] - ETA: 0s - loss: 0.6586 - root_mean_squared_error: 0.3197Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6595 - root_mean_squared_error: 0.3198 - val_loss: 0.7096 - val_root_mean_squared_error: 0.3579\n",
      "Epoch 96/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6573 - root_mean_squared_error: 0.3178Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6583 - root_mean_squared_error: 0.3189 - val_loss: 0.7095 - val_root_mean_squared_error: 0.3578\n",
      "Epoch 97/100\n",
      "207/210 [============================>.] - ETA: 0s - loss: 0.6603 - root_mean_squared_error: 0.3201Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6601 - root_mean_squared_error: 0.3203 - val_loss: 0.7093 - val_root_mean_squared_error: 0.3577\n",
      "Epoch 98/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6587 - root_mean_squared_error: 0.3186Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6599 - root_mean_squared_error: 0.3201 - val_loss: 0.7093 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 99/100\n",
      "163/210 [======================>.......] - ETA: 0s - loss: 0.6600 - root_mean_squared_error: 0.3183Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6590 - root_mean_squared_error: 0.3195 - val_loss: 0.7094 - val_root_mean_squared_error: 0.3577\n",
      "Epoch 100/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6583 - root_mean_squared_error: 0.3180Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6589 - root_mean_squared_error: 0.3194 - val_loss: 0.7095 - val_root_mean_squared_error: 0.3578\n"
     ]
    }
   ],
   "source": [
    "# Memulai training\n",
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_test, y_test),\n",
    "    callbacks = [myCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('model_metrics')\n",
    "plt.ylabel('root_mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Id          int64\n",
      "Place_Id         int64\n",
      "Place_Ratings    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "place_df = update[['Place_Id','Place_Name','new_category','Rating','Price']]\n",
    "place_df.columns = ['id','place_name','category','rating','price']\n",
    "df = rat.copy()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df.User_Id.sample(1).iloc[0]\n",
    "place_visited_by_user = df[df.User_Id == user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat data lokasi yang belum dikunjungi user\n",
    "place_not_rated = place_df[~place_df['id'].isin(\n",
    "    place_visited_by_user.Place_Id.values)]['id']\n",
    "place_not_rated = list(\n",
    "    set(place_not_rated).intersection(set(place_to_place_encoded.keys()))\n",
    ")\n",
    "\n",
    "place_not_rated = [\n",
    "    [place_to_place_encoded.get(x)] for x in place_not_rated]\n",
    "user_encoder = user_to_user_encoded.get(user_id)\n",
    "user_place_array = np.hstack(\n",
    "    ([[user_encoder]] * len(place_not_rated), place_not_rated)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "Ledok Sambi : ['Alam', 'Petualangan']\n",
      "Desa Wisata Kelor : ['Alam', 'Keluarga']\n",
      "Gedung Sate : ['Budaya']\n",
      "Pasar Baru : ['Budaya']\n",
      "Sam Poo Kong Temple : ['Budaya', 'Budaya']\n"
     ]
    }
   ],
   "source": [
    "ratings = model.predict(user_place_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-5:][::-1]\n",
    "recommended_place_ids = [\n",
    "    place_encoded_to_place.get(place_not_rated[x][0]) for x in top_ratings_indices\n",
    "]\n",
    " \n",
    "# print('Daftar rekomendasi untuk: {}'.format('User ' + str(user_id)))\n",
    "# print('===' * 15,'\\n')\n",
    "# print('----' * 15)\n",
    "# print('Tempat dengan rating wisata paling tinggi dari user')\n",
    "# print('----' * 15)\n",
    " \n",
    "top_place_user = (\n",
    "    place_visited_by_user.sort_values(\n",
    "        by = 'Place_Ratings',\n",
    "        ascending=False\n",
    "    )\n",
    "    .head(5)\n",
    "    .Place_Id.values\n",
    ")\n",
    " \n",
    "place_df_rows = place_df[place_df['id'].isin(top_place_user)]\n",
    "for row in place_df_rows.itertuples():\n",
    "    print(row.place_name, ':', row.category)\n",
    "\n",
    "# print('')\n",
    "# print('----' * 15)\n",
    "# print('Top 5 place recommendation')\n",
    "# print('----' * 15)\n",
    " \n",
    "cf_recommendation = place_df[place_df['id'].isin(recommended_place_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Monumen Yogya Kembali</td>\n",
       "      <td>['Budaya']</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>Puncak Gunung Api Purba - Nglanggeran</td>\n",
       "      <td>['Alam', 'Petualangan']</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>322</td>\n",
       "      <td>Bukit Jamur</td>\n",
       "      <td>['Alam', 'Relaksasi']</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>Candi Gedong Songo</td>\n",
       "      <td>['Budaya', 'Sejarah']</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>416</td>\n",
       "      <td>Keraton Surabaya</td>\n",
       "      <td>['Sejarah', 'Budaya']</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             place_name                 category  \\\n",
       "96    97                  Monumen Yogya Kembali               ['Budaya']   \n",
       "138  139  Puncak Gunung Api Purba - Nglanggeran  ['Alam', 'Petualangan']   \n",
       "321  322                            Bukit Jamur    ['Alam', 'Relaksasi']   \n",
       "334  335                     Candi Gedong Songo    ['Budaya', 'Sejarah']   \n",
       "415  416                       Keraton Surabaya    ['Sejarah', 'Budaya']   \n",
       "\n",
       "     rating  price  \n",
       "96      4.5  15000  \n",
       "138     4.7  10000  \n",
       "321     4.2      0  \n",
       "334     4.5  10000  \n",
       "415     4.4      0  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29140\\2547154286.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cf_recommendation.drop([\"place_name\", \"category\", \"rating\", \"price\"], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cf_recommendation.drop([\"place_name\", \"category\", \"rating\", \"price\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_scoring(df):\n",
    "    # this function will return score for each user recommended items\n",
    "    df['score'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29140\\2018131887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['score'] = 1\n"
     ]
    }
   ],
   "source": [
    "cf_recommendation = give_scoring(cf_recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  score\n",
       "96    97      1\n",
       "138  139      1\n",
       "321  322      1\n",
       "334  335      1\n",
       "415  416      1"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_recommendation.to_csv('../data/output/cf_recommendation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
