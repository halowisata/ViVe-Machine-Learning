{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Semarang, Jawa Tengah</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cirebon, Jawa Barat</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bekasi, Jawa Barat</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>296</td>\n",
       "      <td>Lampung, Sumatera Selatan</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>Palembang, Sumatera Selatan</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>Bogor, Jawa Barat</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>Sragen, Jawa Tengah</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>Ponorogo, Jawa Timur</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_Id                     Location  Age\n",
       "0          1        Semarang, Jawa Tengah   20\n",
       "1          2           Bekasi, Jawa Barat   21\n",
       "2          3          Cirebon, Jawa Barat   23\n",
       "3          4           Bekasi, Jawa Barat   21\n",
       "4          5    Lampung, Sumatera Selatan   20\n",
       "..       ...                          ...  ...\n",
       "295      296    Lampung, Sumatera Selatan   31\n",
       "296      297  Palembang, Sumatera Selatan   39\n",
       "297      298            Bogor, Jawa Barat   38\n",
       "298      299          Sragen, Jawa Tengah   27\n",
       "299      300         Ponorogo, Jawa Timur   26\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = pd.read_csv(\"../data/datasets/user.csv\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings\n",
       "0           1       179              3\n",
       "1           1       344              2\n",
       "2           1         5              5\n",
       "3           1       373              3\n",
       "4           1       101              4\n",
       "...       ...       ...            ...\n",
       "9995      300       425              2\n",
       "9996      300        64              4\n",
       "9997      300       311              3\n",
       "9998      300       279              4\n",
       "9999      300       163              2\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat = pd.read_csv(\"../data/datasets/tourism_rating.csv\")\n",
    "rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time_Minutes</th>\n",
       "      <th>Coordinate</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>new_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monumen Nasional</td>\n",
       "      <td>Monumen Nasional atau yang populer disingkat d...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>20000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>{'lat': -6.1753924, 'lng': 106.8271528}</td>\n",
       "      <td>-6.175392</td>\n",
       "      <td>106.827153</td>\n",
       "      <td>['Budaya', 'Keluarga']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Kota Tua</td>\n",
       "      <td>Kota tua di Jakarta, yang juga bernama Kota Tu...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>{'lat': -6.137644799999999, 'lng': 106.8171245}</td>\n",
       "      <td>-6.137645</td>\n",
       "      <td>106.817125</td>\n",
       "      <td>['Budaya']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dunia Fantasi</td>\n",
       "      <td>Dunia Fantasi atau disebut juga Dufan adalah t...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>270000</td>\n",
       "      <td>4.6</td>\n",
       "      <td>360.0</td>\n",
       "      <td>{'lat': -6.125312399999999, 'lng': 106.8335377}</td>\n",
       "      <td>-6.125312</td>\n",
       "      <td>106.833538</td>\n",
       "      <td>['Hiburan', 'Keluarga']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Taman Mini Indonesia Indah (TMII)</td>\n",
       "      <td>Taman Mini Indonesia Indah merupakan suatu kaw...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -6.302445899999999, 'lng': 106.8951559}</td>\n",
       "      <td>-6.302446</td>\n",
       "      <td>106.895156</td>\n",
       "      <td>['Budaya', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlantis Water Adventure</td>\n",
       "      <td>Atlantis Water Adventure atau dikenal dengan A...</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>94000</td>\n",
       "      <td>4.5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>{'lat': -6.12419, 'lng': 106.839134}</td>\n",
       "      <td>-6.124190</td>\n",
       "      <td>106.839134</td>\n",
       "      <td>['Petualangan', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>433</td>\n",
       "      <td>Museum Mpu Tantular</td>\n",
       "      <td>Museum Negeri Mpu Tantular adalah sebuah museu...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>{'lat': -7.4338593, 'lng': 112.7199058}</td>\n",
       "      <td>-7.433859</td>\n",
       "      <td>112.719906</td>\n",
       "      <td>['Sejarah', 'Budaya']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>434</td>\n",
       "      <td>Taman Bungkul</td>\n",
       "      <td>Taman Bungkul adalah taman wisata kota yang te...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.291346799999999, 'lng': 112.7398218}</td>\n",
       "      <td>-7.291347</td>\n",
       "      <td>112.739822</td>\n",
       "      <td>['Alam', 'Relaksasi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>435</td>\n",
       "      <td>Taman Air Mancur Menari Kenjeran</td>\n",
       "      <td>Air mancur menari atau dancing fountain juga a...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>{'lat': -7.2752955, 'lng': 112.7549381}</td>\n",
       "      <td>-7.275296</td>\n",
       "      <td>112.754938</td>\n",
       "      <td>['Alam', 'Hiburan']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>Taman Flora Bratang Surabaya</td>\n",
       "      <td>Taman Flora adalah salah satu taman kota di Su...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.294330299999999, 'lng': 112.7617534}</td>\n",
       "      <td>-7.294330</td>\n",
       "      <td>112.761753</td>\n",
       "      <td>['Alam', 'Relaksasi']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>437</td>\n",
       "      <td>Gereja Perawan Maria Tak Berdosa Surabaya</td>\n",
       "      <td>Gereja Katolik Kelahiran Santa Perawan Maria m...</td>\n",
       "      <td>Surabaya</td>\n",
       "      <td>10000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'lat': -7.2420758, 'lng': 112.7368158}</td>\n",
       "      <td>-7.242076</td>\n",
       "      <td>112.736816</td>\n",
       "      <td>['Budaya']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Place_Id                                 Place_Name  \\\n",
       "0           1                           Monumen Nasional   \n",
       "1           2                                   Kota Tua   \n",
       "2           3                              Dunia Fantasi   \n",
       "3           4          Taman Mini Indonesia Indah (TMII)   \n",
       "4           5                   Atlantis Water Adventure   \n",
       "..        ...                                        ...   \n",
       "432       433                        Museum Mpu Tantular   \n",
       "433       434                              Taman Bungkul   \n",
       "434       435           Taman Air Mancur Menari Kenjeran   \n",
       "435       436               Taman Flora Bratang Surabaya   \n",
       "436       437  Gereja Perawan Maria Tak Berdosa Surabaya   \n",
       "\n",
       "                                           Description      City   Price  \\\n",
       "0    Monumen Nasional atau yang populer disingkat d...   Jakarta   20000   \n",
       "1    Kota tua di Jakarta, yang juga bernama Kota Tu...   Jakarta       0   \n",
       "2    Dunia Fantasi atau disebut juga Dufan adalah t...   Jakarta  270000   \n",
       "3    Taman Mini Indonesia Indah merupakan suatu kaw...   Jakarta   10000   \n",
       "4    Atlantis Water Adventure atau dikenal dengan A...   Jakarta   94000   \n",
       "..                                                 ...       ...     ...   \n",
       "432  Museum Negeri Mpu Tantular adalah sebuah museu...  Surabaya    2000   \n",
       "433  Taman Bungkul adalah taman wisata kota yang te...  Surabaya       0   \n",
       "434  Air mancur menari atau dancing fountain juga a...  Surabaya       0   \n",
       "435  Taman Flora adalah salah satu taman kota di Su...  Surabaya       0   \n",
       "436  Gereja Katolik Kelahiran Santa Perawan Maria m...  Surabaya   10000   \n",
       "\n",
       "     Rating  Time_Minutes                                       Coordinate  \\\n",
       "0       4.6          15.0          {'lat': -6.1753924, 'lng': 106.8271528}   \n",
       "1       4.6          90.0  {'lat': -6.137644799999999, 'lng': 106.8171245}   \n",
       "2       4.6         360.0  {'lat': -6.125312399999999, 'lng': 106.8335377}   \n",
       "3       4.5           NaN  {'lat': -6.302445899999999, 'lng': 106.8951559}   \n",
       "4       4.5          60.0             {'lat': -6.12419, 'lng': 106.839134}   \n",
       "..      ...           ...                                              ...   \n",
       "432     4.4          45.0          {'lat': -7.4338593, 'lng': 112.7199058}   \n",
       "433     4.6           NaN  {'lat': -7.291346799999999, 'lng': 112.7398218}   \n",
       "434     4.4          45.0          {'lat': -7.2752955, 'lng': 112.7549381}   \n",
       "435     4.6           NaN  {'lat': -7.294330299999999, 'lng': 112.7617534}   \n",
       "436     4.8           NaN          {'lat': -7.2420758, 'lng': 112.7368158}   \n",
       "\n",
       "          Lat        Long                new_category  \n",
       "0   -6.175392  106.827153      ['Budaya', 'Keluarga']  \n",
       "1   -6.137645  106.817125                  ['Budaya']  \n",
       "2   -6.125312  106.833538     ['Hiburan', 'Keluarga']  \n",
       "3   -6.302446  106.895156       ['Budaya', 'Hiburan']  \n",
       "4   -6.124190  106.839134  ['Petualangan', 'Hiburan']  \n",
       "..        ...         ...                         ...  \n",
       "432 -7.433859  112.719906       ['Sejarah', 'Budaya']  \n",
       "433 -7.291347  112.739822       ['Alam', 'Relaksasi']  \n",
       "434 -7.275296  112.754938         ['Alam', 'Hiburan']  \n",
       "435 -7.294330  112.761753       ['Alam', 'Relaksasi']  \n",
       "436 -7.242076  112.736816                  ['Budaya']  \n",
       "\n",
       "[437 rows x 11 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update = pd.read_csv('../data/datasets/updated/tourism_with_id_updated.csv')\n",
    "update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list User_Id :  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300]\n",
      "encoded User_Id :  {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299}\n",
      "decode angka ke User_Id :  {0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 14, 14: 15, 15: 16, 16: 17, 17: 18, 18: 19, 19: 20, 20: 21, 21: 22, 22: 23, 23: 24, 24: 25, 25: 26, 26: 27, 27: 28, 28: 29, 29: 30, 30: 31, 31: 32, 32: 33, 33: 34, 34: 35, 35: 36, 36: 37, 37: 38, 38: 39, 39: 40, 40: 41, 41: 42, 42: 43, 43: 44, 44: 45, 45: 46, 46: 47, 47: 48, 48: 49, 49: 50, 50: 51, 51: 52, 52: 53, 53: 54, 54: 55, 55: 56, 56: 57, 57: 58, 58: 59, 59: 60, 60: 61, 61: 62, 62: 63, 63: 64, 64: 65, 65: 66, 66: 67, 67: 68, 68: 69, 69: 70, 70: 71, 71: 72, 72: 73, 73: 74, 74: 75, 75: 76, 76: 77, 77: 78, 78: 79, 79: 80, 80: 81, 81: 82, 82: 83, 83: 84, 84: 85, 85: 86, 86: 87, 87: 88, 88: 89, 89: 90, 90: 91, 91: 92, 92: 93, 93: 94, 94: 95, 95: 96, 96: 97, 97: 98, 98: 99, 99: 100, 100: 101, 101: 102, 102: 103, 103: 104, 104: 105, 105: 106, 106: 107, 107: 108, 108: 109, 109: 110, 110: 111, 111: 112, 112: 113, 113: 114, 114: 115, 115: 116, 116: 117, 117: 118, 118: 119, 119: 120, 120: 121, 121: 122, 122: 123, 123: 124, 124: 125, 125: 126, 126: 127, 127: 128, 128: 129, 129: 130, 130: 131, 131: 132, 132: 133, 133: 134, 134: 135, 135: 136, 136: 137, 137: 138, 138: 139, 139: 140, 140: 141, 141: 142, 142: 143, 143: 144, 144: 145, 145: 146, 146: 147, 147: 148, 148: 149, 149: 150, 150: 151, 151: 152, 152: 153, 153: 154, 154: 155, 155: 156, 156: 157, 157: 158, 158: 159, 159: 160, 160: 161, 161: 162, 162: 163, 163: 164, 164: 165, 165: 166, 166: 167, 167: 168, 168: 169, 169: 170, 170: 171, 171: 172, 172: 173, 173: 174, 174: 175, 175: 176, 176: 177, 177: 178, 178: 179, 179: 180, 180: 181, 181: 182, 182: 183, 183: 184, 184: 185, 185: 186, 186: 187, 187: 188, 188: 189, 189: 190, 190: 191, 191: 192, 192: 193, 193: 194, 194: 195, 195: 196, 196: 197, 197: 198, 198: 199, 199: 200, 200: 201, 201: 202, 202: 203, 203: 204, 204: 205, 205: 206, 206: 207, 207: 208, 208: 209, 209: 210, 210: 211, 211: 212, 212: 213, 213: 214, 214: 215, 215: 216, 216: 217, 217: 218, 218: 219, 219: 220, 220: 221, 221: 222, 222: 223, 223: 224, 224: 225, 225: 226, 226: 227, 227: 228, 228: 229, 229: 230, 230: 231, 231: 232, 232: 233, 233: 234, 234: 235, 235: 236, 236: 237, 237: 238, 238: 239, 239: 240, 240: 241, 241: 242, 242: 243, 243: 244, 244: 245, 245: 246, 246: 247, 247: 248, 248: 249, 249: 250, 250: 251, 251: 252, 252: 253, 253: 254, 254: 255, 255: 256, 256: 257, 257: 258, 258: 259, 259: 260, 260: 261, 261: 262, 262: 263, 263: 264, 264: 265, 265: 266, 266: 267, 267: 268, 268: 269, 269: 270, 270: 271, 271: 272, 272: 273, 273: 274, 274: 275, 275: 276, 276: 277, 277: 278, 278: 279, 279: 280, 280: 281, 281: 282, 282: 283, 283: 284, 284: 285, 285: 286, 286: 287, 287: 288, 288: 289, 289: 290, 290: 291, 291: 292, 292: 293, 293: 294, 294: 295, 295: 296, 296: 297, 297: 298, 298: 299, 299: 300}\n"
     ]
    }
   ],
   "source": [
    "user_ids = rat['User_Id'].unique().tolist()\n",
    "print('list User_Id : ', user_ids)\n",
    "\n",
    "user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "print('encoded User_Id : ', user_to_user_encoded)\n",
    "\n",
    "user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}\n",
    "print('decode angka ke User_Id : ', user_encoded_to_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list Place_Id :  [179, 344, 5, 373, 101, 312, 258, 20, 154, 393, 103, 208, 89, 405, 41, 336, 67, 292, 222, 76, 428, 15, 246, 265, 21, 328, 307, 302, 48, 147, 2, 322, 23, 85, 371, 78, 111, 107, 185, 413, 389, 437, 105, 176, 407, 281, 167, 384, 426, 390, 367, 166, 18, 321, 262, 223, 17, 319, 310, 421, 202, 283, 250, 118, 54, 70, 33, 227, 86, 249, 131, 382, 193, 104, 24, 128, 134, 228, 237, 100, 198, 50, 376, 268, 242, 82, 348, 409, 88, 4, 377, 43, 91, 44, 14, 406, 383, 229, 290, 294, 309, 74, 97, 138, 436, 395, 300, 68, 55, 434, 9, 151, 61, 159, 397, 391, 301, 143, 27, 190, 346, 381, 368, 433, 420, 335, 115, 334, 219, 178, 266, 92, 64, 102, 257, 243, 116, 359, 121, 385, 398, 119, 298, 410, 224, 379, 255, 269, 213, 126, 192, 183, 129, 303, 296, 99, 148, 13, 247, 31, 77, 158, 306, 98, 235, 45, 173, 275, 25, 130, 164, 267, 56, 30, 238, 402, 196, 417, 304, 206, 211, 28, 264, 403, 253, 331, 188, 416, 378, 233, 95, 204, 225, 341, 145, 36, 168, 12, 280, 236, 42, 90, 75, 63, 205, 234, 284, 230, 197, 339, 35, 226, 430, 37, 109, 355, 186, 149, 6, 150, 11, 127, 429, 194, 49, 369, 94, 274, 72, 46, 65, 203, 139, 141, 71, 52, 293, 422, 214, 114, 191, 156, 177, 163, 142, 245, 325, 259, 396, 96, 8, 362, 435, 59, 171, 277, 342, 365, 340, 260, 187, 297, 207, 248, 153, 239, 360, 170, 357, 73, 201, 252, 414, 132, 26, 347, 270, 16, 19, 318, 256, 181, 199, 288, 330, 3, 47, 32, 308, 210, 279, 289, 332, 80, 375, 182, 412, 272, 184, 113, 399, 261, 112, 327, 418, 84, 400, 195, 34, 295, 38, 165, 212, 124, 432, 317, 333, 81, 374, 136, 278, 108, 404, 83, 425, 22, 349, 411, 241, 427, 209, 323, 137, 315, 62, 244, 135, 169, 366, 152, 29, 60, 240, 200, 161, 66, 372, 338, 311, 53, 392, 299, 386, 337, 326, 423, 352, 172, 286, 251, 162, 356, 93, 160, 125, 316, 123, 174, 221, 408, 263, 358, 353, 401, 364, 215, 110, 144, 40, 291, 431, 120, 216, 313, 157, 282, 231, 324, 329, 345, 39, 273, 122, 79, 388, 380, 343, 254, 117, 133, 1, 354, 287, 155, 285, 58, 69, 305, 218, 220, 189, 106, 87, 351, 363, 175, 180, 415, 387, 394, 424, 146, 232, 314, 320, 276, 217, 57, 51, 361, 419, 271, 370, 350, 10, 7, 140]\n",
      "encoded Place_Id :  {179: 0, 344: 1, 5: 2, 373: 3, 101: 4, 312: 5, 258: 6, 20: 7, 154: 8, 393: 9, 103: 10, 208: 11, 89: 12, 405: 13, 41: 14, 336: 15, 67: 16, 292: 17, 222: 18, 76: 19, 428: 20, 15: 21, 246: 22, 265: 23, 21: 24, 328: 25, 307: 26, 302: 27, 48: 28, 147: 29, 2: 30, 322: 31, 23: 32, 85: 33, 371: 34, 78: 35, 111: 36, 107: 37, 185: 38, 413: 39, 389: 40, 437: 41, 105: 42, 176: 43, 407: 44, 281: 45, 167: 46, 384: 47, 426: 48, 390: 49, 367: 50, 166: 51, 18: 52, 321: 53, 262: 54, 223: 55, 17: 56, 319: 57, 310: 58, 421: 59, 202: 60, 283: 61, 250: 62, 118: 63, 54: 64, 70: 65, 33: 66, 227: 67, 86: 68, 249: 69, 131: 70, 382: 71, 193: 72, 104: 73, 24: 74, 128: 75, 134: 76, 228: 77, 237: 78, 100: 79, 198: 80, 50: 81, 376: 82, 268: 83, 242: 84, 82: 85, 348: 86, 409: 87, 88: 88, 4: 89, 377: 90, 43: 91, 91: 92, 44: 93, 14: 94, 406: 95, 383: 96, 229: 97, 290: 98, 294: 99, 309: 100, 74: 101, 97: 102, 138: 103, 436: 104, 395: 105, 300: 106, 68: 107, 55: 108, 434: 109, 9: 110, 151: 111, 61: 112, 159: 113, 397: 114, 391: 115, 301: 116, 143: 117, 27: 118, 190: 119, 346: 120, 381: 121, 368: 122, 433: 123, 420: 124, 335: 125, 115: 126, 334: 127, 219: 128, 178: 129, 266: 130, 92: 131, 64: 132, 102: 133, 257: 134, 243: 135, 116: 136, 359: 137, 121: 138, 385: 139, 398: 140, 119: 141, 298: 142, 410: 143, 224: 144, 379: 145, 255: 146, 269: 147, 213: 148, 126: 149, 192: 150, 183: 151, 129: 152, 303: 153, 296: 154, 99: 155, 148: 156, 13: 157, 247: 158, 31: 159, 77: 160, 158: 161, 306: 162, 98: 163, 235: 164, 45: 165, 173: 166, 275: 167, 25: 168, 130: 169, 164: 170, 267: 171, 56: 172, 30: 173, 238: 174, 402: 175, 196: 176, 417: 177, 304: 178, 206: 179, 211: 180, 28: 181, 264: 182, 403: 183, 253: 184, 331: 185, 188: 186, 416: 187, 378: 188, 233: 189, 95: 190, 204: 191, 225: 192, 341: 193, 145: 194, 36: 195, 168: 196, 12: 197, 280: 198, 236: 199, 42: 200, 90: 201, 75: 202, 63: 203, 205: 204, 234: 205, 284: 206, 230: 207, 197: 208, 339: 209, 35: 210, 226: 211, 430: 212, 37: 213, 109: 214, 355: 215, 186: 216, 149: 217, 6: 218, 150: 219, 11: 220, 127: 221, 429: 222, 194: 223, 49: 224, 369: 225, 94: 226, 274: 227, 72: 228, 46: 229, 65: 230, 203: 231, 139: 232, 141: 233, 71: 234, 52: 235, 293: 236, 422: 237, 214: 238, 114: 239, 191: 240, 156: 241, 177: 242, 163: 243, 142: 244, 245: 245, 325: 246, 259: 247, 396: 248, 96: 249, 8: 250, 362: 251, 435: 252, 59: 253, 171: 254, 277: 255, 342: 256, 365: 257, 340: 258, 260: 259, 187: 260, 297: 261, 207: 262, 248: 263, 153: 264, 239: 265, 360: 266, 170: 267, 357: 268, 73: 269, 201: 270, 252: 271, 414: 272, 132: 273, 26: 274, 347: 275, 270: 276, 16: 277, 19: 278, 318: 279, 256: 280, 181: 281, 199: 282, 288: 283, 330: 284, 3: 285, 47: 286, 32: 287, 308: 288, 210: 289, 279: 290, 289: 291, 332: 292, 80: 293, 375: 294, 182: 295, 412: 296, 272: 297, 184: 298, 113: 299, 399: 300, 261: 301, 112: 302, 327: 303, 418: 304, 84: 305, 400: 306, 195: 307, 34: 308, 295: 309, 38: 310, 165: 311, 212: 312, 124: 313, 432: 314, 317: 315, 333: 316, 81: 317, 374: 318, 136: 319, 278: 320, 108: 321, 404: 322, 83: 323, 425: 324, 22: 325, 349: 326, 411: 327, 241: 328, 427: 329, 209: 330, 323: 331, 137: 332, 315: 333, 62: 334, 244: 335, 135: 336, 169: 337, 366: 338, 152: 339, 29: 340, 60: 341, 240: 342, 200: 343, 161: 344, 66: 345, 372: 346, 338: 347, 311: 348, 53: 349, 392: 350, 299: 351, 386: 352, 337: 353, 326: 354, 423: 355, 352: 356, 172: 357, 286: 358, 251: 359, 162: 360, 356: 361, 93: 362, 160: 363, 125: 364, 316: 365, 123: 366, 174: 367, 221: 368, 408: 369, 263: 370, 358: 371, 353: 372, 401: 373, 364: 374, 215: 375, 110: 376, 144: 377, 40: 378, 291: 379, 431: 380, 120: 381, 216: 382, 313: 383, 157: 384, 282: 385, 231: 386, 324: 387, 329: 388, 345: 389, 39: 390, 273: 391, 122: 392, 79: 393, 388: 394, 380: 395, 343: 396, 254: 397, 117: 398, 133: 399, 1: 400, 354: 401, 287: 402, 155: 403, 285: 404, 58: 405, 69: 406, 305: 407, 218: 408, 220: 409, 189: 410, 106: 411, 87: 412, 351: 413, 363: 414, 175: 415, 180: 416, 415: 417, 387: 418, 394: 419, 424: 420, 146: 421, 232: 422, 314: 423, 320: 424, 276: 425, 217: 426, 57: 427, 51: 428, 361: 429, 419: 430, 271: 431, 370: 432, 350: 433, 10: 434, 7: 435, 140: 436}\n",
      "decode angka ke Place_Id :  {0: 179, 1: 344, 2: 5, 3: 373, 4: 101, 5: 312, 6: 258, 7: 20, 8: 154, 9: 393, 10: 103, 11: 208, 12: 89, 13: 405, 14: 41, 15: 336, 16: 67, 17: 292, 18: 222, 19: 76, 20: 428, 21: 15, 22: 246, 23: 265, 24: 21, 25: 328, 26: 307, 27: 302, 28: 48, 29: 147, 30: 2, 31: 322, 32: 23, 33: 85, 34: 371, 35: 78, 36: 111, 37: 107, 38: 185, 39: 413, 40: 389, 41: 437, 42: 105, 43: 176, 44: 407, 45: 281, 46: 167, 47: 384, 48: 426, 49: 390, 50: 367, 51: 166, 52: 18, 53: 321, 54: 262, 55: 223, 56: 17, 57: 319, 58: 310, 59: 421, 60: 202, 61: 283, 62: 250, 63: 118, 64: 54, 65: 70, 66: 33, 67: 227, 68: 86, 69: 249, 70: 131, 71: 382, 72: 193, 73: 104, 74: 24, 75: 128, 76: 134, 77: 228, 78: 237, 79: 100, 80: 198, 81: 50, 82: 376, 83: 268, 84: 242, 85: 82, 86: 348, 87: 409, 88: 88, 89: 4, 90: 377, 91: 43, 92: 91, 93: 44, 94: 14, 95: 406, 96: 383, 97: 229, 98: 290, 99: 294, 100: 309, 101: 74, 102: 97, 103: 138, 104: 436, 105: 395, 106: 300, 107: 68, 108: 55, 109: 434, 110: 9, 111: 151, 112: 61, 113: 159, 114: 397, 115: 391, 116: 301, 117: 143, 118: 27, 119: 190, 120: 346, 121: 381, 122: 368, 123: 433, 124: 420, 125: 335, 126: 115, 127: 334, 128: 219, 129: 178, 130: 266, 131: 92, 132: 64, 133: 102, 134: 257, 135: 243, 136: 116, 137: 359, 138: 121, 139: 385, 140: 398, 141: 119, 142: 298, 143: 410, 144: 224, 145: 379, 146: 255, 147: 269, 148: 213, 149: 126, 150: 192, 151: 183, 152: 129, 153: 303, 154: 296, 155: 99, 156: 148, 157: 13, 158: 247, 159: 31, 160: 77, 161: 158, 162: 306, 163: 98, 164: 235, 165: 45, 166: 173, 167: 275, 168: 25, 169: 130, 170: 164, 171: 267, 172: 56, 173: 30, 174: 238, 175: 402, 176: 196, 177: 417, 178: 304, 179: 206, 180: 211, 181: 28, 182: 264, 183: 403, 184: 253, 185: 331, 186: 188, 187: 416, 188: 378, 189: 233, 190: 95, 191: 204, 192: 225, 193: 341, 194: 145, 195: 36, 196: 168, 197: 12, 198: 280, 199: 236, 200: 42, 201: 90, 202: 75, 203: 63, 204: 205, 205: 234, 206: 284, 207: 230, 208: 197, 209: 339, 210: 35, 211: 226, 212: 430, 213: 37, 214: 109, 215: 355, 216: 186, 217: 149, 218: 6, 219: 150, 220: 11, 221: 127, 222: 429, 223: 194, 224: 49, 225: 369, 226: 94, 227: 274, 228: 72, 229: 46, 230: 65, 231: 203, 232: 139, 233: 141, 234: 71, 235: 52, 236: 293, 237: 422, 238: 214, 239: 114, 240: 191, 241: 156, 242: 177, 243: 163, 244: 142, 245: 245, 246: 325, 247: 259, 248: 396, 249: 96, 250: 8, 251: 362, 252: 435, 253: 59, 254: 171, 255: 277, 256: 342, 257: 365, 258: 340, 259: 260, 260: 187, 261: 297, 262: 207, 263: 248, 264: 153, 265: 239, 266: 360, 267: 170, 268: 357, 269: 73, 270: 201, 271: 252, 272: 414, 273: 132, 274: 26, 275: 347, 276: 270, 277: 16, 278: 19, 279: 318, 280: 256, 281: 181, 282: 199, 283: 288, 284: 330, 285: 3, 286: 47, 287: 32, 288: 308, 289: 210, 290: 279, 291: 289, 292: 332, 293: 80, 294: 375, 295: 182, 296: 412, 297: 272, 298: 184, 299: 113, 300: 399, 301: 261, 302: 112, 303: 327, 304: 418, 305: 84, 306: 400, 307: 195, 308: 34, 309: 295, 310: 38, 311: 165, 312: 212, 313: 124, 314: 432, 315: 317, 316: 333, 317: 81, 318: 374, 319: 136, 320: 278, 321: 108, 322: 404, 323: 83, 324: 425, 325: 22, 326: 349, 327: 411, 328: 241, 329: 427, 330: 209, 331: 323, 332: 137, 333: 315, 334: 62, 335: 244, 336: 135, 337: 169, 338: 366, 339: 152, 340: 29, 341: 60, 342: 240, 343: 200, 344: 161, 345: 66, 346: 372, 347: 338, 348: 311, 349: 53, 350: 392, 351: 299, 352: 386, 353: 337, 354: 326, 355: 423, 356: 352, 357: 172, 358: 286, 359: 251, 360: 162, 361: 356, 362: 93, 363: 160, 364: 125, 365: 316, 366: 123, 367: 174, 368: 221, 369: 408, 370: 263, 371: 358, 372: 353, 373: 401, 374: 364, 375: 215, 376: 110, 377: 144, 378: 40, 379: 291, 380: 431, 381: 120, 382: 216, 383: 313, 384: 157, 385: 282, 386: 231, 387: 324, 388: 329, 389: 345, 390: 39, 391: 273, 392: 122, 393: 79, 394: 388, 395: 380, 396: 343, 397: 254, 398: 117, 399: 133, 400: 1, 401: 354, 402: 287, 403: 155, 404: 285, 405: 58, 406: 69, 407: 305, 408: 218, 409: 220, 410: 189, 411: 106, 412: 87, 413: 351, 414: 363, 415: 175, 416: 180, 417: 415, 418: 387, 419: 394, 420: 424, 421: 146, 422: 232, 423: 314, 424: 320, 425: 276, 426: 217, 427: 57, 428: 51, 429: 361, 430: 419, 431: 271, 432: 370, 433: 350, 434: 10, 435: 7, 436: 140}\n"
     ]
    }
   ],
   "source": [
    "place_ids = rat['Place_Id'].unique().tolist()\n",
    "print('list Place_Id : ', place_ids)\n",
    "\n",
    "place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}\n",
    "print('encoded Place_Id : ', place_to_place_encoded)\n",
    "\n",
    "place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}\n",
    "print('decode angka ke Place_Id : ', place_encoded_to_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings\n",
       "0           1       179              3\n",
       "1           1       344              2\n",
       "2           1         5              5\n",
       "3           1       373              3\n",
       "4           1       101              4\n",
       "...       ...       ...            ...\n",
       "9995      300       425              2\n",
       "9996      300        64              4\n",
       "9997      300       311              3\n",
       "9998      300       279              4\n",
       "9999      300       163              2\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "collfil = rat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "collfil['user'] = collfil['User_Id'].map(user_to_user_encoded)\n",
    "collfil['place'] = collfil['Place_Id'].map(place_to_place_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Count: 300\n",
      "Places Count: 437\n",
      "Min rating: 1.0\n",
      "Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_to_user_encoded)\n",
    "num_places = len(place_encoded_to_place)\n",
    "\n",
    "collfil['rating'] = collfil['Place_Ratings'].values.astype(np.float32)\n",
    "\n",
    "min_rating = min(collfil['rating'])\n",
    "max_rating = max(collfil['rating'])\n",
    "\n",
    "print(f'Users Count: {num_users}')\n",
    "print(f'Places Count: {num_places}')\n",
    "print(f'Min rating: {min_rating}')\n",
    "print(f'Max rating: {max_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "      <th>user</th>\n",
       "      <th>place</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>300</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>324</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>300</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>132</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>300</td>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>348</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>300</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "      <td>299</td>\n",
       "      <td>290</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>300</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>299</td>\n",
       "      <td>243</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User_Id  Place_Id  Place_Ratings  user  place  rating\n",
       "0           1       179              3     0      0     3.0\n",
       "1           1       344              2     0      1     2.0\n",
       "2           1         5              5     0      2     5.0\n",
       "3           1       373              3     0      3     3.0\n",
       "4           1       101              4     0      4     4.0\n",
       "...       ...       ...            ...   ...    ...     ...\n",
       "9995      300       425              2   299    324     2.0\n",
       "9996      300        64              4   299    132     4.0\n",
       "9997      300       311              3   299    348     3.0\n",
       "9998      300       279              4   299    290     4.0\n",
       "9999      300       163              2   299    243     2.0\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = collfil[['user', 'place']].values\n",
    "\n",
    "y = collfil['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(tf.keras.Model):\n",
    " \n",
    "  # Insialisasi fungsi\n",
    "  def __init__(self, num_users, num_places, embedding_size, **kwargs):\n",
    "    super(RecommenderNet, self).__init__(**kwargs)\n",
    "    self.num_users = num_users\n",
    "    self.num_places = num_places\n",
    "    self.embedding_size = embedding_size\n",
    "    self.user_embedding = layers.Embedding( # layer embedding user\n",
    "        num_users,\n",
    "        embedding_size,\n",
    "        embeddings_initializer = 'he_normal',\n",
    "        embeddings_regularizer = keras.regularizers.l2(1e-6)\n",
    "    )\n",
    "    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias\n",
    "    self.places_embedding = layers.Embedding( # layer embeddings places\n",
    "        num_places,\n",
    "        embedding_size,\n",
    "        embeddings_initializer = 'he_normal',\n",
    "        embeddings_regularizer = keras.regularizers.l2(1e-6)\n",
    "    )\n",
    "    self.places_bias = layers.Embedding(num_places, 1) # layer embedding places bias\n",
    " \n",
    "  def call(self, inputs):\n",
    "    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1\n",
    "    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2\n",
    "    places_vector = self.places_embedding(inputs[:, 1]) # memanggil layer embedding 3\n",
    "    places_bias = self.places_bias(inputs[:, 1]) # memanggil layer embedding 4\n",
    " \n",
    "    dot_user_places = tf.tensordot(user_vector, places_vector, 2) \n",
    " \n",
    "    x = dot_user_places + user_bias + places_bias\n",
    "    \n",
    "    return tf.nn.sigmoid(x) # activation sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderNet(num_users, num_places, 50) # inisialisasi model\n",
    " \n",
    "# model compile\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0004),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(Callback):    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"Checking val_root_mean_squared_error at end of epoch...\")\n",
    "        if logs['val_root_mean_squared_error'] <= 0.25:\n",
    "               self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "159/210 [=====================>........] - ETA: 0s - loss: 0.6989 - root_mean_squared_error: 0.3479Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.6982 - root_mean_squared_error: 0.3479 - val_loss: 0.6970 - val_root_mean_squared_error: 0.3498\n",
      "Epoch 2/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6975 - root_mean_squared_error: 0.3460Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6979 - root_mean_squared_error: 0.3477 - val_loss: 0.6967 - val_root_mean_squared_error: 0.3496\n",
      "Epoch 3/100\n",
      "165/210 [======================>.......] - ETA: 0s - loss: 0.6958 - root_mean_squared_error: 0.3465Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6956 - root_mean_squared_error: 0.3461 - val_loss: 0.6967 - val_root_mean_squared_error: 0.3496\n",
      "Epoch 4/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6934 - root_mean_squared_error: 0.3453Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6941 - root_mean_squared_error: 0.3450 - val_loss: 0.6968 - val_root_mean_squared_error: 0.3496\n",
      "Epoch 5/100\n",
      "159/210 [=====================>........] - ETA: 0s - loss: 0.6935 - root_mean_squared_error: 0.3453Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6929 - root_mean_squared_error: 0.3441 - val_loss: 0.6970 - val_root_mean_squared_error: 0.3498\n",
      "Epoch 6/100\n",
      "199/210 [===========================>..] - ETA: 0s - loss: 0.6915 - root_mean_squared_error: 0.3441Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6915 - root_mean_squared_error: 0.3431 - val_loss: 0.6971 - val_root_mean_squared_error: 0.3498\n",
      "Epoch 7/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6924 - root_mean_squared_error: 0.3430Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6924 - root_mean_squared_error: 0.3438 - val_loss: 0.6971 - val_root_mean_squared_error: 0.3499\n",
      "Epoch 8/100\n",
      "198/210 [===========================>..] - ETA: 0s - loss: 0.6901 - root_mean_squared_error: 0.3419Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6897 - root_mean_squared_error: 0.3418 - val_loss: 0.6972 - val_root_mean_squared_error: 0.3499\n",
      "Epoch 9/100\n",
      "209/210 [============================>.] - ETA: 0s - loss: 0.6868 - root_mean_squared_error: 0.3397Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6868 - root_mean_squared_error: 0.3397 - val_loss: 0.6974 - val_root_mean_squared_error: 0.3500\n",
      "Epoch 10/100\n",
      "203/210 [============================>.] - ETA: 0s - loss: 0.6882 - root_mean_squared_error: 0.3414Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6881 - root_mean_squared_error: 0.3407 - val_loss: 0.6973 - val_root_mean_squared_error: 0.3500\n",
      "Epoch 11/100\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.6871 - root_mean_squared_error: 0.3400Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6873 - root_mean_squared_error: 0.3401 - val_loss: 0.6971 - val_root_mean_squared_error: 0.3499\n",
      "Epoch 12/100\n",
      "189/210 [==========================>...] - ETA: 0s - loss: 0.6841 - root_mean_squared_error: 0.3376Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6841 - root_mean_squared_error: 0.3378 - val_loss: 0.6972 - val_root_mean_squared_error: 0.3499\n",
      "Epoch 13/100\n",
      "185/210 [=========================>....] - ETA: 0s - loss: 0.6833 - root_mean_squared_error: 0.3372Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6838 - root_mean_squared_error: 0.3375 - val_loss: 0.6975 - val_root_mean_squared_error: 0.3501\n",
      "Epoch 14/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6837 - root_mean_squared_error: 0.3380Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6840 - root_mean_squared_error: 0.3377 - val_loss: 0.6978 - val_root_mean_squared_error: 0.3503\n",
      "Epoch 15/100\n",
      "201/210 [===========================>..] - ETA: 0s - loss: 0.6835 - root_mean_squared_error: 0.3379Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6835 - root_mean_squared_error: 0.3373 - val_loss: 0.6979 - val_root_mean_squared_error: 0.3504\n",
      "Epoch 16/100\n",
      "192/210 [==========================>...] - ETA: 0s - loss: 0.6831 - root_mean_squared_error: 0.3373Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6830 - root_mean_squared_error: 0.3370 - val_loss: 0.6983 - val_root_mean_squared_error: 0.3507\n",
      "Epoch 17/100\n",
      "195/210 [==========================>...] - ETA: 0s - loss: 0.6809 - root_mean_squared_error: 0.3363Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6809 - root_mean_squared_error: 0.3354 - val_loss: 0.6985 - val_root_mean_squared_error: 0.3508\n",
      "Epoch 18/100\n",
      "206/210 [============================>.] - ETA: 0s - loss: 0.6793 - root_mean_squared_error: 0.3340Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 2ms/step - loss: 0.6794 - root_mean_squared_error: 0.3343 - val_loss: 0.6985 - val_root_mean_squared_error: 0.3508\n",
      "Epoch 19/100\n",
      "189/210 [==========================>...] - ETA: 0s - loss: 0.6792 - root_mean_squared_error: 0.3341Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6792 - root_mean_squared_error: 0.3342 - val_loss: 0.6983 - val_root_mean_squared_error: 0.3507\n",
      "Epoch 20/100\n",
      "188/210 [=========================>....] - ETA: 0s - loss: 0.6795 - root_mean_squared_error: 0.3343Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6793 - root_mean_squared_error: 0.3343 - val_loss: 0.6986 - val_root_mean_squared_error: 0.3509\n",
      "Epoch 21/100\n",
      "200/210 [===========================>..] - ETA: 0s - loss: 0.6784 - root_mean_squared_error: 0.3332Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6788 - root_mean_squared_error: 0.3339 - val_loss: 0.6990 - val_root_mean_squared_error: 0.3512\n",
      "Epoch 22/100\n",
      "199/210 [===========================>..] - ETA: 0s - loss: 0.6789 - root_mean_squared_error: 0.3346Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6784 - root_mean_squared_error: 0.3336 - val_loss: 0.6990 - val_root_mean_squared_error: 0.3511\n",
      "Epoch 23/100\n",
      "199/210 [===========================>..] - ETA: 0s - loss: 0.6765 - root_mean_squared_error: 0.3325Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6765 - root_mean_squared_error: 0.3322 - val_loss: 0.6990 - val_root_mean_squared_error: 0.3511\n",
      "Epoch 24/100\n",
      "195/210 [==========================>...] - ETA: 0s - loss: 0.6768 - root_mean_squared_error: 0.3335Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6770 - root_mean_squared_error: 0.3326 - val_loss: 0.6988 - val_root_mean_squared_error: 0.3510\n",
      "Epoch 25/100\n",
      "205/210 [============================>.] - ETA: 0s - loss: 0.6739 - root_mean_squared_error: 0.3303Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6740 - root_mean_squared_error: 0.3304 - val_loss: 0.6992 - val_root_mean_squared_error: 0.3513\n",
      "Epoch 26/100\n",
      "190/210 [==========================>...] - ETA: 0s - loss: 0.6746 - root_mean_squared_error: 0.3307Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 0.6748 - root_mean_squared_error: 0.3310 - val_loss: 0.6994 - val_root_mean_squared_error: 0.3514\n",
      "Epoch 27/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6735 - root_mean_squared_error: 0.3298Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6739 - root_mean_squared_error: 0.3303 - val_loss: 0.6993 - val_root_mean_squared_error: 0.3513\n",
      "Epoch 28/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6732 - root_mean_squared_error: 0.3293Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6733 - root_mean_squared_error: 0.3298 - val_loss: 0.6992 - val_root_mean_squared_error: 0.3513\n",
      "Epoch 29/100\n",
      "189/210 [==========================>...] - ETA: 0s - loss: 0.6711 - root_mean_squared_error: 0.3288Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6721 - root_mean_squared_error: 0.3290 - val_loss: 0.6998 - val_root_mean_squared_error: 0.3517\n",
      "Epoch 30/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6731 - root_mean_squared_error: 0.3287Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6732 - root_mean_squared_error: 0.3298 - val_loss: 0.7002 - val_root_mean_squared_error: 0.3519\n",
      "Epoch 31/100\n",
      "191/210 [==========================>...] - ETA: 0s - loss: 0.6728 - root_mean_squared_error: 0.3297Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6728 - root_mean_squared_error: 0.3295 - val_loss: 0.6999 - val_root_mean_squared_error: 0.3518\n",
      "Epoch 32/100\n",
      "177/210 [========================>.....] - ETA: 0s - loss: 0.6727 - root_mean_squared_error: 0.3295Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6723 - root_mean_squared_error: 0.3291 - val_loss: 0.7001 - val_root_mean_squared_error: 0.3519\n",
      "Epoch 33/100\n",
      "193/210 [==========================>...] - ETA: 0s - loss: 0.6708 - root_mean_squared_error: 0.3284Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6708 - root_mean_squared_error: 0.3280 - val_loss: 0.7005 - val_root_mean_squared_error: 0.3521\n",
      "Epoch 34/100\n",
      "189/210 [==========================>...] - ETA: 0s - loss: 0.6692 - root_mean_squared_error: 0.3261Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6691 - root_mean_squared_error: 0.3268 - val_loss: 0.7008 - val_root_mean_squared_error: 0.3524\n",
      "Epoch 35/100\n",
      "160/210 [=====================>........] - ETA: 0s - loss: 0.6720 - root_mean_squared_error: 0.3269Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6705 - root_mean_squared_error: 0.3278 - val_loss: 0.7008 - val_root_mean_squared_error: 0.3523\n",
      "Epoch 36/100\n",
      "196/210 [===========================>..] - ETA: 0s - loss: 0.6706 - root_mean_squared_error: 0.3283Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6709 - root_mean_squared_error: 0.3281 - val_loss: 0.7014 - val_root_mean_squared_error: 0.3527\n",
      "Epoch 37/100\n",
      "202/210 [===========================>..] - ETA: 0s - loss: 0.6683 - root_mean_squared_error: 0.3256Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6681 - root_mean_squared_error: 0.3260 - val_loss: 0.7019 - val_root_mean_squared_error: 0.3531\n",
      "Epoch 38/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6685 - root_mean_squared_error: 0.3255Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6677 - root_mean_squared_error: 0.3257 - val_loss: 0.7021 - val_root_mean_squared_error: 0.3532\n",
      "Epoch 39/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6678 - root_mean_squared_error: 0.3282Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6690 - root_mean_squared_error: 0.3267 - val_loss: 0.7025 - val_root_mean_squared_error: 0.3535\n",
      "Epoch 40/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6697 - root_mean_squared_error: 0.3273Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6689 - root_mean_squared_error: 0.3266 - val_loss: 0.7029 - val_root_mean_squared_error: 0.3538\n",
      "Epoch 41/100\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.6675 - root_mean_squared_error: 0.3244Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6674 - root_mean_squared_error: 0.3255 - val_loss: 0.7032 - val_root_mean_squared_error: 0.3540\n",
      "Epoch 42/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6674 - root_mean_squared_error: 0.3250Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6675 - root_mean_squared_error: 0.3256 - val_loss: 0.7031 - val_root_mean_squared_error: 0.3539\n",
      "Epoch 43/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6670 - root_mean_squared_error: 0.3236Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6668 - root_mean_squared_error: 0.3251 - val_loss: 0.7035 - val_root_mean_squared_error: 0.3541\n",
      "Epoch 44/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6676 - root_mean_squared_error: 0.3252Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6677 - root_mean_squared_error: 0.3258 - val_loss: 0.7033 - val_root_mean_squared_error: 0.3540\n",
      "Epoch 45/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6640 - root_mean_squared_error: 0.3237Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6652 - root_mean_squared_error: 0.3239 - val_loss: 0.7034 - val_root_mean_squared_error: 0.3541\n",
      "Epoch 46/100\n",
      "174/210 [=======================>......] - ETA: 0s - loss: 0.6676 - root_mean_squared_error: 0.3248Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6666 - root_mean_squared_error: 0.3250 - val_loss: 0.7037 - val_root_mean_squared_error: 0.3542\n",
      "Epoch 47/100\n",
      "156/210 [=====================>........] - ETA: 0s - loss: 0.6660 - root_mean_squared_error: 0.3254Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6661 - root_mean_squared_error: 0.3246 - val_loss: 0.7038 - val_root_mean_squared_error: 0.3543\n",
      "Epoch 48/100\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.6661 - root_mean_squared_error: 0.3250Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6655 - root_mean_squared_error: 0.3242 - val_loss: 0.7039 - val_root_mean_squared_error: 0.3544\n",
      "Epoch 49/100\n",
      "197/210 [===========================>..] - ETA: 0s - loss: 0.6654 - root_mean_squared_error: 0.3247Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6654 - root_mean_squared_error: 0.3241 - val_loss: 0.7038 - val_root_mean_squared_error: 0.3543\n",
      "Epoch 50/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6645 - root_mean_squared_error: 0.3250Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6652 - root_mean_squared_error: 0.3240 - val_loss: 0.7042 - val_root_mean_squared_error: 0.3546\n",
      "Epoch 51/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6659 - root_mean_squared_error: 0.3229Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6644 - root_mean_squared_error: 0.3234 - val_loss: 0.7045 - val_root_mean_squared_error: 0.3547\n",
      "Epoch 52/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6652 - root_mean_squared_error: 0.3236Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6649 - root_mean_squared_error: 0.3237 - val_loss: 0.7046 - val_root_mean_squared_error: 0.3548\n",
      "Epoch 53/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6649 - root_mean_squared_error: 0.3234Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6643 - root_mean_squared_error: 0.3233 - val_loss: 0.7045 - val_root_mean_squared_error: 0.3547\n",
      "Epoch 54/100\n",
      "173/210 [=======================>......] - ETA: 0s - loss: 0.6637 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6638 - root_mean_squared_error: 0.3229 - val_loss: 0.7049 - val_root_mean_squared_error: 0.3551\n",
      "Epoch 55/100\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.6635 - root_mean_squared_error: 0.3225Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6635 - root_mean_squared_error: 0.3227 - val_loss: 0.7051 - val_root_mean_squared_error: 0.3551\n",
      "Epoch 56/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6630 - root_mean_squared_error: 0.3240Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6630 - root_mean_squared_error: 0.3223 - val_loss: 0.7054 - val_root_mean_squared_error: 0.3554\n",
      "Epoch 57/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6652 - root_mean_squared_error: 0.3246Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6643 - root_mean_squared_error: 0.3233 - val_loss: 0.7053 - val_root_mean_squared_error: 0.3553\n",
      "Epoch 58/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6627 - root_mean_squared_error: 0.3224Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6628 - root_mean_squared_error: 0.3221 - val_loss: 0.7055 - val_root_mean_squared_error: 0.3554\n",
      "Epoch 59/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6630 - root_mean_squared_error: 0.3226Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6633 - root_mean_squared_error: 0.3225 - val_loss: 0.7057 - val_root_mean_squared_error: 0.3556\n",
      "Epoch 60/100\n",
      "202/210 [===========================>..] - ETA: 0s - loss: 0.6624 - root_mean_squared_error: 0.3221Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6624 - root_mean_squared_error: 0.3219 - val_loss: 0.7062 - val_root_mean_squared_error: 0.3559\n",
      "Epoch 61/100\n",
      "198/210 [===========================>..] - ETA: 0s - loss: 0.6633 - root_mean_squared_error: 0.3223Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6632 - root_mean_squared_error: 0.3225 - val_loss: 0.7063 - val_root_mean_squared_error: 0.3559\n",
      "Epoch 62/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6639 - root_mean_squared_error: 0.3214Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6633 - root_mean_squared_error: 0.3226 - val_loss: 0.7067 - val_root_mean_squared_error: 0.3562\n",
      "Epoch 63/100\n",
      "192/210 [==========================>...] - ETA: 0s - loss: 0.6621 - root_mean_squared_error: 0.3216Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6618 - root_mean_squared_error: 0.3214 - val_loss: 0.7069 - val_root_mean_squared_error: 0.3563\n",
      "Epoch 64/100\n",
      "172/210 [=======================>......] - ETA: 0s - loss: 0.6627 - root_mean_squared_error: 0.3237Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6626 - root_mean_squared_error: 0.3220 - val_loss: 0.7071 - val_root_mean_squared_error: 0.3564\n",
      "Epoch 65/100\n",
      "161/210 [======================>.......] - ETA: 0s - loss: 0.6624 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6621 - root_mean_squared_error: 0.3217 - val_loss: 0.7069 - val_root_mean_squared_error: 0.3563\n",
      "Epoch 66/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6619 - root_mean_squared_error: 0.3205Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6617 - root_mean_squared_error: 0.3214 - val_loss: 0.7074 - val_root_mean_squared_error: 0.3566\n",
      "Epoch 67/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6615 - root_mean_squared_error: 0.3213Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6628 - root_mean_squared_error: 0.3222 - val_loss: 0.7074 - val_root_mean_squared_error: 0.3566\n",
      "Epoch 68/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6606 - root_mean_squared_error: 0.3204Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6615 - root_mean_squared_error: 0.3212 - val_loss: 0.7075 - val_root_mean_squared_error: 0.3566\n",
      "Epoch 69/100\n",
      "201/210 [===========================>..] - ETA: 0s - loss: 0.6614 - root_mean_squared_error: 0.3206Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6612 - root_mean_squared_error: 0.3209 - val_loss: 0.7079 - val_root_mean_squared_error: 0.3569\n",
      "Epoch 70/100\n",
      "164/210 [======================>.......] - ETA: 0s - loss: 0.6621 - root_mean_squared_error: 0.3223Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6619 - root_mean_squared_error: 0.3215 - val_loss: 0.7082 - val_root_mean_squared_error: 0.3571\n",
      "Epoch 71/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6628 - root_mean_squared_error: 0.3205Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6624 - root_mean_squared_error: 0.3218 - val_loss: 0.7085 - val_root_mean_squared_error: 0.3572\n",
      "Epoch 72/100\n",
      "170/210 [=======================>......] - ETA: 0s - loss: 0.6616 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6616 - root_mean_squared_error: 0.3213 - val_loss: 0.7086 - val_root_mean_squared_error: 0.3573\n",
      "Epoch 73/100\n",
      "182/210 [=========================>....] - ETA: 0s - loss: 0.6597 - root_mean_squared_error: 0.3196Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6599 - root_mean_squared_error: 0.3200 - val_loss: 0.7089 - val_root_mean_squared_error: 0.3575\n",
      "Epoch 74/100\n",
      "204/210 [============================>.] - ETA: 0s - loss: 0.6603 - root_mean_squared_error: 0.3202Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6604 - root_mean_squared_error: 0.3205 - val_loss: 0.7091 - val_root_mean_squared_error: 0.3576\n",
      "Epoch 75/100\n",
      "158/210 [=====================>........] - ETA: 0s - loss: 0.6604 - root_mean_squared_error: 0.3212Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6606 - root_mean_squared_error: 0.3205 - val_loss: 0.7095 - val_root_mean_squared_error: 0.3579\n",
      "Epoch 76/100\n",
      "200/210 [===========================>..] - ETA: 0s - loss: 0.6609 - root_mean_squared_error: 0.3207Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6605 - root_mean_squared_error: 0.3205 - val_loss: 0.7097 - val_root_mean_squared_error: 0.3580\n",
      "Epoch 77/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6611 - root_mean_squared_error: 0.3198Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6612 - root_mean_squared_error: 0.3210 - val_loss: 0.7101 - val_root_mean_squared_error: 0.3583\n",
      "Epoch 78/100\n",
      "165/210 [======================>.......] - ETA: 0s - loss: 0.6596 - root_mean_squared_error: 0.3189Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6618 - root_mean_squared_error: 0.3214 - val_loss: 0.7102 - val_root_mean_squared_error: 0.3583\n",
      "Epoch 79/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6609 - root_mean_squared_error: 0.3209Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6605 - root_mean_squared_error: 0.3204 - val_loss: 0.7103 - val_root_mean_squared_error: 0.3584\n",
      "Epoch 80/100\n",
      "205/210 [============================>.] - ETA: 0s - loss: 0.6614 - root_mean_squared_error: 0.3207Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6614 - root_mean_squared_error: 0.3211 - val_loss: 0.7102 - val_root_mean_squared_error: 0.3583\n",
      "Epoch 81/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6606 - root_mean_squared_error: 0.3218Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6610 - root_mean_squared_error: 0.3209 - val_loss: 0.7105 - val_root_mean_squared_error: 0.3585\n",
      "Epoch 82/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6599 - root_mean_squared_error: 0.3190Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6598 - root_mean_squared_error: 0.3200 - val_loss: 0.7105 - val_root_mean_squared_error: 0.3585\n",
      "Epoch 83/100\n",
      "190/210 [==========================>...] - ETA: 0s - loss: 0.6590 - root_mean_squared_error: 0.3190Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6594 - root_mean_squared_error: 0.3197 - val_loss: 0.7106 - val_root_mean_squared_error: 0.3585\n",
      "Epoch 84/100\n",
      "157/210 [=====================>........] - ETA: 0s - loss: 0.6578 - root_mean_squared_error: 0.3191Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6597 - root_mean_squared_error: 0.3199 - val_loss: 0.7106 - val_root_mean_squared_error: 0.3585\n",
      "Epoch 85/100\n",
      "164/210 [======================>.......] - ETA: 0s - loss: 0.6609 - root_mean_squared_error: 0.3220Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6613 - root_mean_squared_error: 0.3211 - val_loss: 0.7106 - val_root_mean_squared_error: 0.3585\n",
      "Epoch 86/100\n",
      "165/210 [======================>.......] - ETA: 0s - loss: 0.6588 - root_mean_squared_error: 0.3199Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6590 - root_mean_squared_error: 0.3194 - val_loss: 0.7108 - val_root_mean_squared_error: 0.3587\n",
      "Epoch 87/100\n",
      "166/210 [======================>.......] - ETA: 0s - loss: 0.6602 - root_mean_squared_error: 0.3196Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6597 - root_mean_squared_error: 0.3200 - val_loss: 0.7110 - val_root_mean_squared_error: 0.3588\n",
      "Epoch 88/100\n",
      "169/210 [=======================>......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3214Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6609 - root_mean_squared_error: 0.3209 - val_loss: 0.7112 - val_root_mean_squared_error: 0.3589\n",
      "Epoch 89/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6602 - root_mean_squared_error: 0.3202Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6610 - root_mean_squared_error: 0.3209 - val_loss: 0.7114 - val_root_mean_squared_error: 0.3590\n",
      "Epoch 90/100\n",
      "171/210 [=======================>......] - ETA: 0s - loss: 0.6603 - root_mean_squared_error: 0.3201Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6597 - root_mean_squared_error: 0.3199 - val_loss: 0.7115 - val_root_mean_squared_error: 0.3591\n",
      "Epoch 91/100\n",
      "162/210 [======================>.......] - ETA: 0s - loss: 0.6597 - root_mean_squared_error: 0.3193Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6599 - root_mean_squared_error: 0.3201 - val_loss: 0.7115 - val_root_mean_squared_error: 0.3591\n",
      "Epoch 92/100\n",
      "167/210 [======================>.......] - ETA: 0s - loss: 0.6600 - root_mean_squared_error: 0.3208Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6602 - root_mean_squared_error: 0.3203 - val_loss: 0.7116 - val_root_mean_squared_error: 0.3591\n",
      "Epoch 93/100\n",
      "168/210 [=======================>......] - ETA: 0s - loss: 0.6600 - root_mean_squared_error: 0.3196Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6598 - root_mean_squared_error: 0.3199 - val_loss: 0.7117 - val_root_mean_squared_error: 0.3592\n",
      "Epoch 94/100\n",
      "165/210 [======================>.......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3206Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6598 - root_mean_squared_error: 0.3200 - val_loss: 0.7119 - val_root_mean_squared_error: 0.3593\n",
      "Epoch 95/100\n",
      "163/210 [======================>.......] - ETA: 0s - loss: 0.6601 - root_mean_squared_error: 0.3206Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6595 - root_mean_squared_error: 0.3198 - val_loss: 0.7119 - val_root_mean_squared_error: 0.3593\n",
      "Epoch 96/100\n",
      "154/210 [=====================>........] - ETA: 0s - loss: 0.6574 - root_mean_squared_error: 0.3196Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6599 - root_mean_squared_error: 0.3201 - val_loss: 0.7123 - val_root_mean_squared_error: 0.3596\n",
      "Epoch 97/100\n",
      "184/210 [=========================>....] - ETA: 0s - loss: 0.6591 - root_mean_squared_error: 0.3193Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6594 - root_mean_squared_error: 0.3197 - val_loss: 0.7124 - val_root_mean_squared_error: 0.3597\n",
      "Epoch 98/100\n",
      "178/210 [========================>.....] - ETA: 0s - loss: 0.6585 - root_mean_squared_error: 0.3185Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 2ms/step - loss: 0.6598 - root_mean_squared_error: 0.3200 - val_loss: 0.7124 - val_root_mean_squared_error: 0.3596\n",
      "Epoch 99/100\n",
      "207/210 [============================>.] - ETA: 0s - loss: 0.6593 - root_mean_squared_error: 0.3198Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6596 - root_mean_squared_error: 0.3198 - val_loss: 0.7124 - val_root_mean_squared_error: 0.3596\n",
      "Epoch 100/100\n",
      "161/210 [======================>.......] - ETA: 0s - loss: 0.6597 - root_mean_squared_error: 0.3199Checking val_root_mean_squared_error at end of epoch...\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.6589 - root_mean_squared_error: 0.3193 - val_loss: 0.7124 - val_root_mean_squared_error: 0.3597\n"
     ]
    }
   ],
   "source": [
    "# Memulai training\n",
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_test, y_test),\n",
    "    callbacks = [myCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('model_metrics')\n",
    "plt.ylabel('root_mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_Id          int64\n",
      "Place_Id         int64\n",
      "Place_Ratings    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "place_df = update[['Place_Id','Place_Name','new_category','Rating','Price']]\n",
    "place_df.columns = ['id','place_name','category','rating','price']\n",
    "df = rat.copy()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Id</th>\n",
       "      <th>Place_Id</th>\n",
       "      <th>Place_Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_Id  Place_Id  Place_Ratings\n",
       "0        1       179              3"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df.User_Id.sample(1).iloc[0]\n",
    "place_visited_by_user = df[df.User_Id == user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monumen Nasional</td>\n",
       "      <td>['Budaya', 'Keluarga']</td>\n",
       "      <td>4.6</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Kota Tua</td>\n",
       "      <td>['Budaya']</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dunia Fantasi</td>\n",
       "      <td>['Hiburan', 'Keluarga']</td>\n",
       "      <td>4.6</td>\n",
       "      <td>270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        place_name                 category  rating   price\n",
       "0   1  Monumen Nasional   ['Budaya', 'Keluarga']     4.6   20000\n",
       "1   2          Kota Tua               ['Budaya']     4.6       0\n",
       "2   3     Dunia Fantasi  ['Hiburan', 'Keluarga']     4.6  270000"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat data lokasi yang belum dikunjungi user\n",
    "place_not_rated = place_df[~place_df['id'].isin(\n",
    "    place_visited_by_user.Place_Id.values)]['id']\n",
    "place_not_rated = list(\n",
    "    set(place_not_rated).intersection(set(place_to_place_encoded.keys()))\n",
    ")\n",
    "\n",
    "place_not_rated = [\n",
    "    [place_to_place_encoded.get(x)] for x in place_not_rated]\n",
    "user_encoder = user_to_user_encoded.get(user_id)\n",
    "user_place_array = np.hstack(\n",
    "    ([[user_encoder]] * len(place_not_rated), place_not_rated)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "Pasar Taman Puring : ['Budaya']\n",
      "Museum Sonobudoyo Unit I : ['Budaya']\n",
      "Goa Pindul : ['Alam', 'Petualangan']\n",
      "Museum Nike Ardilla : ['Budaya']\n",
      "Sunrise Point Cukul : ['Alam', 'Petualangan']\n"
     ]
    }
   ],
   "source": [
    "ratings = model.predict(user_place_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-5:][::-1]\n",
    "recommended_place_ids = [\n",
    "    place_encoded_to_place.get(place_not_rated[x][0]) for x in top_ratings_indices\n",
    "]\n",
    " \n",
    "# print('Daftar rekomendasi untuk: {}'.format('User ' + str(user_id)))\n",
    "# print('===' * 15,'\\n')\n",
    "# print('----' * 15)\n",
    "# print('Tempat dengan rating wisata paling tinggi dari user')\n",
    "# print('----' * 15)\n",
    " \n",
    "top_place_user = (\n",
    "    place_visited_by_user.sort_values(\n",
    "        by = 'Place_Ratings',\n",
    "        ascending=False\n",
    "    )\n",
    "    .head(5)\n",
    "    .Place_Id.values\n",
    ")\n",
    " \n",
    "place_df_rows = place_df[place_df['id'].isin(top_place_user)]\n",
    "for row in place_df_rows.itertuples():\n",
    "    print(row.place_name, ':', row.category)\n",
    "\n",
    "# print('')\n",
    "# print('----' * 15)\n",
    "# print('Top 5 place recommendation')\n",
    "# print('----' * 15)\n",
    " \n",
    "recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>place_name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Monumen Yogya Kembali</td>\n",
       "      <td>['Budaya']</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Taman Pelangi Yogyakarta</td>\n",
       "      <td>['Hiburan', 'Keluarga']</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>Desa Wisata Gamplong</td>\n",
       "      <td>['Alam', 'Budaya']</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>Sanghyang Heuleut</td>\n",
       "      <td>['Alam', 'Petualangan']</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>416</td>\n",
       "      <td>Keraton Surabaya</td>\n",
       "      <td>['Sejarah', 'Budaya']</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                place_name                 category  rating  price\n",
       "96    97     Monumen Yogya Kembali               ['Budaya']     4.5  15000\n",
       "97    98  Taman Pelangi Yogyakarta  ['Hiburan', 'Keluarga']     4.3  15000\n",
       "133  134      Desa Wisata Gamplong       ['Alam', 'Budaya']     4.4  10000\n",
       "299  300         Sanghyang Heuleut  ['Alam', 'Petualangan']     4.4  10000\n",
       "415  416          Keraton Surabaya    ['Sejarah', 'Budaya']     4.4      0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29140\\2817039017.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_place.drop([\"place_name\", \"category\", \"rating\", \"price\"], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "recommended_place.drop([\"place_name\", \"category\", \"rating\", \"price\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_scoring(df):\n",
    "    # this function will return score for each user recommended items\n",
    "    df['score'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_29140\\2018131887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['score'] = 1\n"
     ]
    }
   ],
   "source": [
    "recommended_place = give_scoring(recommended_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>416</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  score\n",
       "96    97      1\n",
       "97    98      1\n",
       "133  134      1\n",
       "299  300      1\n",
       "415  416      1"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_place"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
